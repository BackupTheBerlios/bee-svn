<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head>
<meta name="Author" content="Ralf Nolting">
<meta name="GENERATOR" content="Microsoft FrontPage 4.0">
<meta name="fdse-index-as" content="http://www.spec.org/mail2001/docs/whitepaper.html"><title>SpecMail2001 ArchWP</title>

<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link rel="stylesheet" href="printstyle.css" type="text/css" media="print">
<link rel="stylesheet" href="ns4style.css" type="text/css" media="screen">
<style type="text/css" media="screen">@import url("/includes/sitestyle.css");</style>
<link rel="home" href="http://www.spec.org/" title="Home">
<link rel="help" href="http://www.spec.org/spec/faq/" title="FAQ">
<link rel="contents" href="http://www.spec.org/contents.html" title="Contents">
<link rel="index" href="http://www.spec.org/permuted.html" title="Site Index">
<link rel="glossary" href="http://www.spec.org/spec/glossary/" title="Glossary">
<link rel="copyright" href="http://www.spec.org/spec/copyright.html" title="Copyright">
<link rel="search" href="http://www.spec.org/search.html" title="Search">
<link rel="stylesheet" type="text/css" href="sstyle.css" title="main">
</head>

<body alink="#a4005a" bgcolor="#fefefe" link="#0000bb" vlink="#4c0077">

<table>
  <tbody><tr>
    <td valign="top"><a href="http://www.spec.org/mail2001/"><img src="./img/mainlogosmall.gif" alt="SPEC logo" border="0"></a></td>
    <td valign="top">
      <h1 align="center"> SPECmail2001 Mail Server Benchmark<br>
        Architecture White Paper </h1>
      <p align="center"> Version 1.00<br>
        Last modified: January 16, 2001 </p>
    </td>
  </tr>
</tbody></table>
<hr align="center" size="1" width="100%">
<!--webbot bot="PurpleText" 
    <TABLE border=1 cellPadding=2 cellSpacing=0>
    <table width="808">
      <CAPTION>Change History</CAPTION>
      <TBODY>
      <TR>
        <TD width="112">Version</TD>
        <TD width="89">Date</TD>
        <TD width="83">Author</TD>
        <TD width="496">Comment</TD></TR>
      <TR>
        <TD width="112">Version 1.0</TD>
        <TD width="89">12/27/2000</TD>
        <TD width="83">Chris Beer</TD>
        <TD width="496">Updated for release on the CD.<br>
          Removed Chapter 9 (since it is not ready yet)<br>
          Removed all highlighting and ToDo comments<br>
          Cleaned up Q&amp;A Section<br>
          Various spelling corrections</TD></TR>
      <TR>
        <TD width="112">Draft 10</TD>
        <TD width="89">11/08/2000</TD>
        <TD width="83">Ralf Nolting</TD>
        <TD width="496">Recent mods are now in blue. <BR>Except for chapter 9, all "Todo" 
          items solved. <BR>The Q&amp;A section needs to be cleaned up after it is 
          clear which items go to <BR>the separate FAQ. Maybe we should also find a 
          less confusing name.</TD></TR>
      <TR>
        <TD width="112">Draft 9</TD>
        <TD width="89">09/17/2000</TD>
        <TD width="83">Ralf Nolting</TD>
        <TD width="496">Notes from Breckenridge, completed notes from Dublin, <BR>added topic 
          "POP retries", <BR>added graphs to "Remote Mail" section, <BR>added Neal 
          Gafter's analytic computation of steady mail store state, <BR>removed some 
          of the material in ch. 9 which reflects old implementation. <BR>All 
          changes since draft 7 are in green color, since draft 8 was never 
        reviewed.</TD></TR>
      <TR>
        <TD width="112">Draft 8</TD>
        <TD width="89">07/14/2000</TD>
        <TD width="83">Ralf Nolting</TD>
        <TD width="496">Included corrections suggested by Chris Beer, <BR>as well as notes 
          from Dublin meeting.</TD></TR>
      <TR>
        <TD width="112">Draft 7</TD>
        <TD width="89">05/04/2000</TD>
        <TD width="83">Ralf Nolting</TD>
        <TD width="496">included changes from Manassas (Mar 2000) meeting; <BR>leaving chap 
          9's internals to Aron <BR>All topics not addressed included as Todo's. 
          <BR>Some old Todo's addressed.</TD></TR>
      <TR>
        <TD width="112">Draft 6</TD>
        <TD width="89">03/08/2000</TD>
        <TD width="83">Ralf Nolting</TD>
        <TD width="496">Added workload consensus, resulting workload calculation, <BR>mail 
          server disk space estimates, relation to benchmark metric.</TD></TR>
      <TR>
        <TD width="112">Draft 5</TD>
        <TD width="89">02/03/2000</TD>
        <TD width="83">Aron Fu <BR>Ralf Nolting</TD>
        <TD width="496">included Aron Fu's internals description in chapter 9 <BR>(this draft 
          was only shared between Ralf and Aron)</TD></TR>
      <TR>
        <TD width="112">Draft 4</TD>
        <TD width="89">01/31/2000</TD>
        <TD width="83">Ralf Nolting</TD>
        <TD width="496">included changes from Sunnyvale (Jan 2000) work group meeting 
          <BR>transformed format into HTML <BR>included Aron Fu's section on Arrival 
          Rate Implementation <BR>(this draft was never published)</TD></TR>
      <TR>
        <TD width="112">Draft 3</TD>
        <TD width="89">11/24/1999</TD>
        <TD width="83">Ralf Nolting</TD>
        <TD width="496">included changes from Albuquerque (Nov 1999) work group meeting</TD></TR>
      <TR>
        <TD width="112">Draft 2</TD>
        <TD width="89">09/27/1999</TD>
        <TD width="83">Ralf Nolting</TD>
        <TD width="496">included changes from Paderborn (Sep 1999) work group meeting</TD></TR>
      <TR>
        <TD width="112">Draft 1</TD>
        <TD width="89">09/01/1999</TD>
        <TD width="83">Ralf Nolting</TD>
        <TD width="496">initial version</TD></TR>
        </TBODY>
      </table>
      
    -->
<h2> Table of Contents </h2>
<blockquote> <a href="#1.">1. Introduction</a>
  <blockquote> <a href="#1.1.">1.1. Overview</a><br>
    <a href="#1.2.">1.2. Organization of this Paper</a><br>
    <a href="#1.3.">1.3. Related Documents</a><br>
    <a href="#1.4.">1.4. Run and Reporting Rules</a> </blockquote>
  <a href="#2.">2. Design Principles</a>
  <blockquote> <a href="#2.1.">2.1. Requirements and Goals</a><br>
    <a href="#2.2.">2.2. Excluded Goals</a> </blockquote>
  <a href="#3.">3. Benchmark Metric: SPECmail2001 Messages per Minute</a>
  <p> <a href="#4.">4. Workload</a> </p>
  <blockquote> <a href="#4.1.">4.1. Basis of Workload Definition</a><br>
    <a href="#4.2.">4.2. Transaction Workload</a>
    <blockquote> <a href="#4.2.1.">4.2.1. User Profile</a>
      <blockquote> <a href="#4.2.1.1.">4.2.1.1. Message Size (MSG_SIZE_DISTRIBUTION)</a><br>
        <a href="#4.2.1.2.">4.2.1.2. Recipient Count (MSG_RECP_DISTRIBUTION)</a> </blockquote>
      <a href="#4.2.2.">4.2.2. Transactions and Parameters per POP/SMTP session</a>
      <blockquote> <a href="#4.2.2.1.">4.2.2.1. SMTP Session</a><br>
        <a href="#4.2.2.2.">4.2.2.2. POP3 Session</a> </blockquote>
      <a href="#4.2.3.">4.2.3. Transaction Workload Calculation</a> </blockquote>
    <a href="#4.3.">4.3. Pre-population of Mail Store</a>
    <blockquote> <a href="#4.3.1.">4.3.1. Pre-populated Mail Store Calculation</a><br>
      <a href="#4.3.2.">4.3.2. Analytical Background</a> </blockquote>
    <a href="#4.4.">4.4. Benchmark Metric Calculation</a><br>
    <a href="#4.5.">4.5. Mail Server Housekeeping Functions</a> </blockquote>
  <a href="#5.">5. Detail Aspects of Workload Simulation</a>
  <blockquote> <a href="#5.1.">5.1. Arrival Rate and Interarrival Time Distribution</a>
    <blockquote> <a href="#5.1.1.">5.1.1. Arrival Rate</a><br>
      <a href="#5.1.2.">5.1.2. Interarrival Time</a> </blockquote>
    <a href="#5.2.">5.2. Traffic to/from Remote Mail Servers</a><br>
    <a href="#5.3.">5.3. POP Retries</a> </blockquote>
  <a href="#6.">6. Quality of Service</a>
  <blockquote> <a href="#6.1.">6.1. Response Times</a><br>
    <a href="#6.2.">6.2. Delivery Times</a><br>
    <a href="#6.3.">6.3. Remote Delivery Times</a><br>
    <a href="#6.4.">6.4. Error Rates</a><br>
    <a href="#6.5.">6.5. Overall QoS Requirement</a> </blockquote>
  <a href="#7.">7. Performance Characterization</a>
  <p> <a href="#8.">8. Components of a Benchmark Setup</a> </p>
  <blockquote> <a href="#8.1.">8.1. System under Test</a><br>
    <a href="#8.2.">8.2. Benchmark Test Client Systems</a> </blockquote>
  <a href="#10.">9. Future Plans</a><br>
  <a href="#QandA">Appendix: Questions and Answers</a> </blockquote>
<h1> <br clear="all">
  <a id="1." name="1."></a>1. Introduction </h1>
<h2> <a id="1.1." name="1.1."></a>1.1. Overview </h2>
<p> SPECmail2001 is a software benchmark designed to measure a system's ability
  to act as a mail server servicing email requests, based on the Internet standard
  protocols SMTP and POP3. The first version concentrates on the Internet Service
  Provider (ISP) class of mail servers, with an overall user count in the range
  of 10,000 to 1,000,000 users. It models POP consumer users. A future version
  will address business users and the IMAP4 protocol. </p>
<p> SPECmail2001 has been developed by the Standard Performance Evaluation Corporation
  (SPEC), a non-profit group of computer vendors, system integrators, universities,
  research organizations, publishers, and consultants. </p>
<p> This paper discusses the benchmark principles and architecture, and the rationale
  behind the key design decisions. It also outlines the workload used in the
  benchmark, and the general steps needed to run a benchmark. However those aspects
  are covered in more detail in other documents. </p>
<h2> <a id="1.2." name="1.2."></a>1.2. Organization of this Paper </h2>
<p> Chapter 2 discusses the basic goals and non-goals of the benchmark. </p>
<p> Chapter 3 introduces the performance metric of SPECmail2001 - messages per
  minute - and how it relates to the transaction mix imposed on the system under
  test.. </p>
<p> Chapter 4 explains the benchmark workload - how it was derived, how it translates
  into configuration parameters for the benchmark tool and size calculations
  for planning a benchmark, and how it relates to the benchmark metric. </p>
<p> Chapter 5 discusses some detail of aspects of the workload generation, namely
  the exact workload put on the server, and how the benchmark simulates communication
  with remote mail servers. </p>
<p> Chapter 6 defines the quality of service requirements of this benchmark. </p>
<p> Chapter 7 presents the 3-point performance characterization provided by this
  benchmark - showing server behavior under target load (100%), as well as under
  lower load (80%) and overload (120%). </p>
<p> Chapter 8 sketches the hardware and software elements used in a SPECmail2001
  benchmark. </p>
<p> Chapter 9 concludes with an outlook into future plans. </p>
<p> An appendix with questions and answers is provided at the end of the paper,
  reflecting discussions that the workgroup has had in the design and implementation
  of this benchmark. This material was deemed relevant enough to be captured
  in this white paper; yet it was eliminated from the main body so as to streamline
  the presentation of what the benchmark is (and not what it is not). Throughout
  the preceding chapters, there are links provided into the Q&amp;A section,
  to indicate how the "off-topic" discussions relate to aspects of
  the benchmark. </p>
<h2> <a id="1.3." name="1.3."></a>1.3. Related Documents </h2>
<ol>
  <li> SPECmail2001 Run and Reporting Rules </li>
  <li> Workload Analysis for Internet Mail Servers </li>
  <li> SPECmail2001 User Guide </li>
  <li> SPECmail2001 Sample Result Disclosure </li>
  <li> SPECmail2001 FAQ </li>
</ol>
<p> All documents can be obtained from the <a href="http://www.spec.org/osg/mail2001/">mail server
    home page</a>. </p>
<h2> <a id="1.4." name="1.4."></a>1.4. Run and Reporting Rules </h2>
<p> The Run and Reporting Rules for the SPECmail2001 benchmark are spelled out
  in a separate document. They ensure execution of the benchmark in a controlled
  environment. The goal is repeatability by third parties with reasonable resources
  and knowledge. The rules maximize the comparability of results, leveling the
  playing field as much as possible. They also define which information needs
  to be included in published results, and which supporting information needs
  to be submitted to the SPEC community for potential review. </p>
<p> Under the terms of the SPECmail2001 license, SPECmail2001 results may not
  be publicly reported unless they are run in compliance with the Run and Reporting
  Rules. Results published at the SPEC web site have been reviewed and approved
  by the SPECmail committee. For more information on publishing results at the
  SPEC web site, please send e-mail to: info@spec.org. The Run and Reporting
  Rules may be found on the SPEC web site; they are also part of the SPECmail2001
  distribution kit. </p>
<h1> <a id="2." name="2."></a>2. Design of the SPECmail2001 Benchmark </h1>
<p> SPECmail2001 is a mail server benchmark testing the capacity of a system
  as a mail server, while serving requests according to the Internet standard
  mail protocols SMTP (RFC821) and POP3 (RFC1939). SMTP is the standard for sending
  email from clients to servers, and between servers. POP3 is a protocol for
  mail access and retrieval by the user. </p>
<p> SPECmail2001's model for a POP user is a consumer customer of an ISP.
  The details of a consumer-type user's behavior will be discussed in a later
  chapter in this paper. Mail server user behavior varies greatly. It is therefore
  very important to define the type of assumed user, before discussing how many
  users a mail server can handle. </p>
<p> SPECmail2001 simulates the load which would be generated by a certain user
  population, and observes the mail server behavior under that load. It enforces
  the adherence to a required level of quality of service. The goal is to simulate
  realistic mail server operation, to maximize the usefulness of the benchmark
  results as guidelines for actual sizing decisions. </p>
<h2> <a id="2.1." name="2.1."></a>2.1. Requirements and Goals </h2>
<p> The key goal of SPECmail2001 is to show mail server performance in a realistic
  context. This means </p>
<ol>
  <li> <strong>Appropriate Mail Store</strong> </li>
  <li style="list-style-type: none; list-style-image: none; list-style-position: outside;"> <br>
    A mail server which handles the transaction load of a large number of users
      needs to also be able to hold the mail data for the same amount of users.
      This includes a mailbox per user, as well as a defined number of messages
      per user.<br>
&nbsp; </li>
  <li> <strong>Arrival Rate</strong> </li>
  <li style="list-style-type: none; list-style-image: none; list-style-position: outside;"> <br>
    New requests are being issued against the server according to an arrival
      rate pattern modeled after real world observations.<br>
&nbsp; </li>
  <li> <strong>Modem Simulation</strong> </li>
  <li style="list-style-type: none; list-style-image: none; list-style-position: outside;"> <br>
    A percentage of clients is simulated as having low bandwidth connections,
      which extends the session duration and therefore increases parallel session
      count.<br>
&nbsp; </li>
  <li> <strong>Workload according to Real World Data</strong> </li>
  <li style="list-style-type: none; list-style-image: none; list-style-position: outside;"> <br>
    The simulated workload (such as messages sent and received per day, the message
      size distribution, the mailbox check frequency) is based on measurements
      and experience.<br>
&nbsp; </li>
  <li> <strong>Peak Hour Simulation</strong> </li>
  <li style="list-style-type: none; list-style-image: none; list-style-position: outside;"> <br>
    Mail traffic is distributed unevenly over the day. Sizing must focus on coping
      with the peak load. Therefore, the benchmark mail server load simulates
      the peak hour of the day.<br>
&nbsp; </li>
  <li> <strong>Realistic Operation</strong> </li>
  <li style="list-style-type: none; list-style-image: none; list-style-position: outside;"> <br>
    The mail server is required to operate realistically, e.g. perform at least
      a defined level of logging which many ISPs would use in practice. As is
      the rule in all SPEC benchmarks, no benchmark-specific optimizations are
      allowed. </li>
</ol>
<h2> <a id="2.2." name="2.2."></a>2.2. Excluded Goals </h2>
<strong><u>Explicitly excluded goals and limitations</u> in the scope of SPECmail2001
are:</strong>
<ol>
  <li> The benchmark does not require that there be 1,000's of small, remotely
    connected email clients. Instead, it allows simulation of the email clients
    on a small number of server-sized, locally connected client systems, in order
    to make the benchmark execution practical. </li><br>
  <li> The benchmark does not include administrational activities like on-line
    backup and account provisioning. These are hard to standardize, and - more
    importantly - they do not necessarily happen during the peak hour of daily
    operation. </li><br>
  <li> Besides provisioning, the benchmark does not include modification to account
    data or deletion of accounts. These activities, although commonplace in the
    day-to-day operation of a mail server, are seen as testing the directory
    service rather than the mail server itself. SPECmail2001 emphasizes mail
    server benchmarking, and includes a directory server in the system-under-test
    only to the minimum extent necessary to handle normal mail flow. </li><br>
  <li> The benchmark does not cover relay operation (forwarding of incoming SMTP
    traffic to other, remote MTAs). <u>It does include simulation of messages from
    local users to remote MTAs, as well as incoming mail from remote MTAs</u>. Relay
    operation was excluded since it is often handled by separate MTA systems. </li><br>
  <li> There is no requirement for high availability or disaster recovery measures;
    this was beyond the scope of the benchmark. </li><br>
  <li> The mail server is not required to perform any extended features, like
    virus scanning, spam filtering, handling of mailing lists, security measures,
    multiple folders per mailbox. This was beyond the scope of the benchmark. </li><br>
  <li> SMTP sessions can normally send one or several messages per session. <u>The
    benchmark restricts itself to one message.</u> This reduced the development effort
    on the benchmark tool, and was also consistent with early mail server traffic
    data evaluation. </li><br>
  <li> <u>The benchmark does not include handling of MIME messages (messages with
    attachments)</u>. MIME messages do not get special treatment by the mail server
    under the SMTP or POP protocols; they do get special treatment by the server
    under the IMAP protocol, which is outside the scope of this version of the
    benchmark. (Note, mail clients may pay special attention to MIME messages
    under all protocols, but that does not affect the benchmark). </li><br>
  <li> The rules for preparing the benchmark do not require any aging of the
    mail store, beyond establishing the initial workload. In reality, mail stores
    may deteriorate over time, e.g. through file system or database fragmentation.
    The rationale is that a fresh mail store is at least a good comparison base,
    and that any realistic aging would inflate the benchmark execution effort. </li><br>
</ol>
<table border="0" cellspacing="0">
  <tbody><tr>
    <td> <em><font size="-1">See also Q&amp;A section:</font></em> </td>
    <td> <em><a href="#Q10"><font size="-1">Why does SPECmail2001 not include
            IMAP4 users?</font></a></em> </td>
  </tr>
  <tr>
    <td> </td>
    <td> <em><a href="#Q11"><font color="#006600" size="-1">Does SPECmail2001
            consider WebMail?</font></a></em> </td>
  </tr>
  <tr>
    <td> </td>
    <td> <em><a href="#Q3"><font color="#006600" size="-1">Why doesn't the
            benchmark push as hard as possible and report the achieved throughput?</font></a></em> </td>
  </tr>
  <tr>
    <td> </td>
    <td> <em><a href="#Q12"><font size="-1">What constitutes a mail server?</font></a></em> </td>
  </tr>
</tbody></table>
<h1> <a id="3." name="3."></a>3. Benchmark Metric: </h1>
<center>
  <h1> SPECmail2001 Messages per Minute </h1>
</center>
<p> Capacity at acceptable quality of service (QoS) is the basis of the performance
  metric of this benchmark. Acceptable QoS is measured by interactive response
  time of the mail server to each protocol step (see <a href="#6.">chapter 6</a>). This metric is therefore </p>
<center>
  <p> &nbsp;<strong>SPECmail2001 messages per minute</strong> </p>
</center>
<p> One SPECmail2001 message per minute includes a mix of transactions that a
  mail server needs to perform on a single message, from first receiving it to
  finally deleting it. This transaction mix depends on the workload, which will
  be defined later on in this document. For the following workload </p>
<blockquote>
  <ol>
    <li> <tt>&nbsp;each user sends two message per day, to two recipients</tt> </li>
    <li> <tt>&nbsp;each user receives two messages per day</tt> </li>
    <li> <tt>&nbsp;each user checks his/her mailbox four times a day</tt> </li>
    <li> <tt>&nbsp;all messages get retrieved and deleted</tt> </li>
  </ol>
</blockquote>
<p> the transaction mix for <strong>1 SPECmail2001 message per minute</strong> consists
  of the following elementary mail server operations:<br>
&nbsp; </p>
<center>
  <table border="1" cellspacing="0">
    <tbody><tr>
      <td> Transaction Type </td>
      <td> Transaction Count per Minute </td>
    </tr>
    <tr>
      <td> message sent by user </td>
      <td align="center"> 1 </td>
    </tr>
    <tr>
      <td> message sent to remote mail server </td>
      <td align="center"> 0.9 </td>
    </tr>
    <tr>
      <td> message received from remote mail server </td>
      <td align="center"> 0.9 </td>
    </tr>
    <tr>
      <td> mailbox check </td>
      <td align="center"> 2 </td>
    </tr>
    <tr>
      <td> retrieval and deletion of message </td>
      <td align="center"> 2 </td>
    </tr>
    </tbody><caption align="bottom">
    Table 1: Transaction count per "Message per Minute"
    </caption>
  </table>
</center>
<p> This metric cannot be compared to any other similarly named benchmark metric
  which does not follow exactly that workload definition and the same execution
  rules. Every aspect of each may affect the benchmark outcome.<br>
&nbsp; </p>
<table border="0" cellspacing="0">
  <tbody><tr>
    <td> <em><font size="-1">See also Q&amp;A section:</font></em> </td>
    <td> <em><a href="#Q1"><font size="-1">Why isn't the benchmark metric "Number
            of Users"?</font></a></em> </td>
  </tr>
  <tr>
    <td> </td>
    <td> <em><a href="#Q2"><font size="-1">Why isn't the benchmark metric "Parallel
            Sessions"?</font></a></em> </td>
  </tr>
</tbody></table>
<h1> <a id="4." name="4."></a>4. Workload </h1>
<p> The SPECmail2001 workload has two parts: <u>the pre-population of the mail store</u>
  and the <u>transaction workload during runtime</u>. Both depend on the targeted benchmark
  rating. </p>
<blockquote> It may be helpful at this point to list the basic steps of running
  a SPECmail2001 benchmark. </blockquote>
<div style="margin-left: 2em;">
  <ol>
    <li> Pre-establish and pre-populate mail store according to initial workload
      (or restore backup copy) </li>
    <li> Start from a cold system (processes, file systems, databases), so that
      all caches are clean </li>
    <li> Verify mail store contents: message distribution across mailboxes, message
      size distribution </li>
    <li> Run warm-up period (no measurements) </li>
    <li> Run benchmark period (runtime workload, measurements taken) </li>
    <li> Shutdown phase of benchmark and Report Generation </li>
    <li style="list-style-type: none; list-style-image: none; list-style-position: outside;"> &nbsp; </li>
  </ol>
  The actual process is a bit more complex - refer to the <a href="#1.4.">Run and Reporting Rules</a>
  for details. </div>
<p> The definition of a pre-population of the mail server ensures that a system
  claiming to handle the transaction load for 1 million users is also capable
  to handle the mail data related to 1 million users. <u>The pre-population consists
  of a message distribution across all mailboxes.</u> <u>The runtime load defines the
  number and kind of transactions that will be issued to the server during the
  benchmark run.</u> </p>
<p> The SPECmail2001 benchmark is designed so that it generates a steady mail
  server state: over time, <a href="#3.">it adds as many messages to the mail store as it removes.</a>
  Note, however, that insertion and deletion happens on mailboxes which are independently
  (and randomly) selected - i.e. "steady state" does not mean that
  the contents of the mail store, or any part of it, will be static. Just <u>the
  overall volume should only fluctuate within certain limits.</u> This behavior is
  not quite realistic - a production mail server will "breathe" over
  time, and it may actually grow over time, due to increasing user demands. However,
  this behavior is deemed close enough to reality, and greatly simplifies the
  running of series of benchmarks on the same mail store setup. </p>
<p> A stable mail store's contents can be determined fully by the transaction
  workload - we'll therefore discuss the <a href="#4.2.">transaction workload first</a>, and
  determine the <a href="#4.3.">resulting mail store pre-population after that. </a></p>
<h2> <a id="4.1." name="4.1."></a>4.1. Basis of Workload Definition </h2>
<p> The workload profile has been determined based on observing actual systems
  in production. At the time of this writing, it appears very difficult to impossible
  to provide the background data of this workload definition for public review,
  due to business aspects of the companies involved. The workload definition
  is therefore based on a two-pronged approach: </p>
<ol>
  <li> The working group was able to obtain a few actual mail server log files.
    The University of Pavia performed statistical analysis on this data. These
    were used to determine the "microscopic" behavior of the benchmark.
    In particular, the shape of the message size distribution, and the shape
    of the inter arrival time distribution are based on that study. </li>
  <li> Some of the members of the working group have direct day-to-day experience
    with mail server operation in production. Although these individuals were
    not able to obtain actual, hard data from customer sites (see above), they
    did provide their general experience for typical load data. These data were
    collected and combined into an "expert consensus", and are used
    to determine the "macroscopic" behavior of the benchmark. The average
    message size, as well as the average arrival rate are based on these data. </li>
</ol>
<p> The workload definition is believed to be currently realistic for the indicated
  user type, consumer POP user. The average user profile is, however, a moving
  target, affected by changing user behavior, evolving technology, etc. </p>
<blockquote>
  <blockquote>
    <blockquote> <strong>Note: The SPEC consortium is interested in extending
        its base of field data for this workload characterization. If you are
        an ISP willing to share traffic data with SPEC, then please contact the
        work group.</strong> </blockquote>
  </blockquote>
</blockquote>
<h2> <a id="4.2." name="4.2."></a><font color="#000000">4.2. Transaction Workload</font> </h2>
<p> The <u>Transaction Workload defines the number and type of transactions issued
  against the system under test during the measurement phase of the benchmark</u>.
  It scales linearly with the number of users and with the SPECmail2001 messages
  per minute performance metric.<br><br> <b>Its parameters are: </b></p>
<ol>
  <li> number of new SMTP sessions established per second </li>
  <li> number of new POP sessions established per second </li>
  <li> message size distribution </li>
  <li> client connection bandwidth distribution </li>
  <li> percentage of SMTP traffic to/from remote domain </li>
</ol>
<h3> <a id="4.2.1." name="4.2.1."></a><font color="#000000">4.2.1. User Profile</font> </h3>
<p> The definition of the transaction workload starts with an assessment of the
  per-user, per-day load profile. The following tables show assumptions for that
  profile, as well as the semantics for the elements in that profile. A third
  column shows the related configuration parameter of the benchmark tool - names
  in <font size="-1">ALL_UPPER_CASE</font> are actual configuration parameters
  of the benchmark tool, names using UpperAndLower case are inserted only for
  editorial purposes.<br>
&nbsp;<br>
&nbsp; </p>
<center>
  <table border="1" cellpadding="2" cellspacing="0">
    <tbody><tr>
      <td> <u>Parameter</u> </td>
      <td> <u>Workgroup Estimate</u> </td>
      <td> <u>related benchmark tool parameters</u></td>
    </tr>
    <tr>
      <td> <i>number of users (defined by test sponsor)</i> </td>
      <td align="center"> example: 1 million </td>
      <td> <font size="-1">USER_START, USER_END</font> <br>
        <font size="-1">UserCount := USER_END - USER_START + 1</font> </td>
    </tr>
    <tr>
      <td> <i>messages sent per day</i> </td>
      <td align="center"> 2 </td>
      <td> <font size="-1">MSG_SENT_PER_DAY</font> </td>
    </tr>
    <tr>
      <td> <i>average recipients per message</i> </td>
      <td align="center"> 2 </td>
      <td> <font size="-1">MSG_RECP_DISTRIBUTION</font> </td>
    </tr>
    <tr>
      <td> <i>messages received per day</i> </td>
      <td align="center"> 4 </td>
      <td> <font size="-1">(MsgRcvd)</font> </td>
    </tr>
    <tr>
      <td> mailbox checks per day </td>
      <td align="center"> 4 </td>
      <td> <font size="-1">POP_CHECKS_PER_DAY</font> </td>
    </tr>
    <tr>
      <td> % of mailbox checks which don't download messages </td>
      <td align="center"> 75% </td>
      <td> <font size="-1">(REPEATED_POP_CHECKS_PER_DAY)</font> </td>
    </tr>
    <tr>
      <td> average message size in KB </td>
      <td align="center"> 25 </td>
      <td> <font size="-1">MsgSz,</font> <br>
        <font size="-1">MSG_SIZE_DISTRIBUTION</font> </td>
    </tr>
    <tr>
      <td> % of users using modems (56Kbit) </td>
      <td align="center"> 90% </td>
      <td> <font size="-1">DATA_RATE_DISTRIBUTION</font> </td>
    </tr>
    <tr>
      <td> % of daily activities during busiest hour </td>
      <td align="center"> 15% </td>
      <td> <font size="-1">PEAK_LOAD_PERCENT</font> </td>
    </tr>
    <tr>
      <td> % of mail to/from remote addresses </td>
      <td align="center">
        <center>
          90%
        </center>
      </td>
      <td> <font size="-1">MSG_DESTINATION_LOCAL_PERCENT</font> </td>
    </tr>
  </tbody></table>
</center>
<p> Explanation of Parameters:<br>
&nbsp; </p>
<table border="1" cellpadding="3" cellspacing="0">
  <tbody><tr>
    <td valign="top"> <strong>UserCount</strong> </td>
    <td>&nbsp; </td>
    <td> This is not a predefined load parameter; rather, it is the user-defined
      goal of a benchmark run. It scales linearly with the benchmark metric. </td>
  </tr>
  <tr>
    <td valign="top"> <strong><font size="-1">MSG_SENT_PER_DAY</font></strong> </td>
    <td> </td>
    <td> The number of messages sent per day per user. </td>
  </tr>
  <tr>
    <td valign="top"> <strong><font size="-1">MSG_RECP_DISTRIBUTION</font></strong> </td>
    <td> </td>
    <td> Number of recipients per message: every SMTP message can be directed
      to multiple users. This parameter affects how many messages are actually
      found in the mail store. </td>
  </tr>
  <tr>
    <td valign="top"> <strong>MsgsRcvd</strong> </td>
    <td> </td>
    <td> Number of messages received, per user and day. While this is a favorite
      parameter to monitor, it is not really an active part of the user behavior:
      every user will receive whatever is in the mailbox. In the case of SPECmail2001,
      it is assumed that the amount of sent and received messages is identical. </td>
  </tr>
  <tr>
    <td valign="top"> <strong><font size="-1">POP_CHECKS_PER_DAY</font></strong> </td>
    <td> </td>
    <td> Number of mailbox checks per day and user. </td>
  </tr>
  <tr>
    <td> <strong><font size="-1">REPEATED_POP_CHECKS_PER_DAY</font></strong> </td>
    <td> </td>
    <td> Number of "repeated" mailbox checks per day and user. Workload
      studies show regularly that POP email users tend to <u>generate a high percentage
      of POP sessions which operate on previously emptied mailboxes and hence
      do not download any messages.</u> The workgroup discussed the fraction of these
      (i.e. PctEmpty), while the benchmark tool implements the actual count of
      each type. <u><font size="-1">REPEATED_PO_CHECKS_PER_DAY</font> must be less than <font size="-1">POP_CHECKS_PER_DAY</font></u> to make sense. </td>
  </tr>
  <tr>
    <td valign="top"> <strong><font size="-1">MSG_SIZE_DISTRIBUTION</font></strong> </td>
    <td> </td>
    <td> Average message size. It should be noted that the actual size of messages
      varies greatly - a vast majority is very small. A large part of this average
      size results from a minority of large messages. Accordingly, SPECmail2001
      actually defines a mail size distribution, of which this is the average. </td>
  </tr>
  <tr>
    <td valign="top"> <strong><font size="-1">DATA_RATE_DISTRIBUTION</font></strong> </td>
    <td> </td>
    <td> Fraction of users using slow modem connections - the rest is assumed
      to be connected via low-latency, high-bandwidth links. The main effect
      of slow connections is to drag out mail sessions in length, which in turn
      affects the dynamic memory footprint of the mail server, as well as CPU
      usage efficiency. </td>
  </tr>
  <tr>
    <td valign="top"> <strong><font size="-1">PEAK_LOAD_PERCENT</font></strong> </td>
    <td> </td>
    <td> SPECmail2001 simulates the peak hour of mail traffic. This factor is
      key to translate the per-day user profile to the per-second transaction
      load definition. </td>
  </tr>
  <tr>
    <td valign="top"> <strong><font size="-1">MSG_DESTINATION_LOCAL_PERCENT</font></strong> </td>
    <td> </td>
    <td> Fraction of the mail traffic going to /coming in from the internet.
      SPECmail2001 assumes the two are the same - overall the mail server under
      test produces as much external mail as it consumes. </td>
  </tr>
</tbody></table>
<br>
<p> &nbsp; <a id="4.2.1.1." name="4.2.1.1."></a><h4><font color="#000000">4.2.1.1. Message Size (MSG_SIZE_DISTRIBUTION)</font></h4> </p>
<p> <u>The benchmark tool generates test messages on the fly.</u> The size of each message
  is determined according to a distribution resulting from user data evaluation,
  which counted messages from buckets of certain sizes. The characteristic of
  the distribution is that the vast majority of messages is small, while there
  are also a few very large messages in the mix. The average message size is
  24.5KB.<br>
&nbsp;<br>
&nbsp; </p>
<center>
  <table border="1" cellspacing="0" cols="2" width="50%">
    <tbody><tr>
      <td align="center"> Message Size (KB) </td>
      <td align="center"> Percentage in Mix </td>
    </tr>
    <tr>
      <td align="center"> 1 </td>
      <td align="center"> 10.20% </td>
    </tr>
    <tr>
      <td align="center"> 2 </td>
      <td align="center"> 30.71% </td>
    </tr>
    <tr>
      <td align="center"> 3 </td>
      <td align="center"> 20.59% </td>
    </tr>
    <tr>
      <td align="center"> 4 </td>
      <td align="center"> 10.78% </td>
    </tr>
    <tr>
      <td align="center"> 5 </td>
      <td align="center"> 5.88% </td>
    </tr>
    <tr>
      <td align="center"> 6 </td>
      <td align="center"> 3.74% </td>
    </tr>
    <tr>
      <td align="center"> 10 </td>
      <td align="center"> 7.44% </td>
    </tr>
    <tr>
      <td align="center"> 100 </td>
      <td align="center"> 9.79% </td>
    </tr>
    <tr>
      <td align="center"> 1000 </td>
      <td align="center"> 0.69% </td>
    </tr>
    <tr>
      <td align="center"> 2,675 </td>
      <td align="center"> 0.18% </td>
    </tr>
  </tbody></table>
</center>
<img alt="" src="./img/MsgSzDist1.gif" height="623" width="911"> 
<h4> <a id="4.2.1.2." name="4.2.1.2."></a><h4><font color="#000000">4.2.1.2.
      Recipient Count (MSG_RECP_DISTRIBUTION)</font></h4> </h4>
<p> Each message gets sent to one or more recipients. The vast majority of messages
  gets sent to one recipient, while others get sent to up to 20 recipients. The
  distribution is controlled by the configuration parameter MSG_RECP_DISTRIBUTION.
  The fixed setting is given in the table and chart below.<br>
&nbsp; </p>
<center>
  <table border="1" cellspacing="0" cols="2" width="50%">
    <tbody><tr align="center" valign="bottom">
      <td> <font face="Arial">Recipient Count</font> </td>
      <td> <font face="Arial">Percentage</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">1</font> </td>
      <td style=""> <font face="Arial">85.73%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">2</font> </td>
      <td style=""> <font face="Arial">1.66%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">3</font> </td>
      <td style=""> <font face="Arial">1.49%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">4</font> </td>
      <td style=""> <font face="Arial">1.34%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">5</font> </td>
      <td style=""> <font face="Arial">1.20%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">6</font> </td>
      <td style=""> <font face="Arial">1.08%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">7</font> </td>
      <td style=""> <font face="Arial">0.97%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">8</font> </td>
      <td style=""> <font face="Arial">0.88%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">9</font> </td>
      <td style=""> <font face="Arial">0.79%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">10</font> </td>
      <td style=""> <font face="Arial">0.71%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">11</font> </td>
      <td style=""> <font face="Arial">0.64%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">12</font> </td>
      <td style=""> <font face="Arial">0.58%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">13</font> </td>
      <td style=""> <font face="Arial">0.52%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">14</font> </td>
      <td style=""> <font face="Arial">0.47%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">15</font> </td>
      <td style=""> <font face="Arial">0.42%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">16</font> </td>
      <td style=""> <font face="Arial">0.38%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">17</font> </td>
      <td style=""> <font face="Arial">0.34%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">18</font> </td>
      <td style=""> <font face="Arial">0.31%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">19</font> </td>
      <td style=""> <font face="Arial">0.28%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">20</font> </td>
      <td style=""> <font face="Arial">0.21%</font> </td>
    </tr>
  </tbody></table>
</center>
<p> <img alt="" src="./img/rcptchart1.gif" height="623" width="911"> </p>
<h3> <a id="4.2.2." name="4.2.2."></a>4.2.2. Transactions and Parameters per
  POP/SMTP session </h3>
<h4> <a id="4.2.2.1." name="4.2.2.1."></a>4.2.2.1. SMTP Session </h4>
<p> An SMTP session connects to the server, receives the banner screen, transmits
  sender, recipients and contents of a message, and disconnects. There are two
  types of SMTP sessions, and there a slight difference how the configuration
  parameters affect each one. </p>
<p> For an SMTP session simulating a message sent by a local user, the configuration
  parameters have the following influence. </p>
<ol>
  <li> The number of recipients is determined according to <strong><font size="-1">MSG_RECP_DISTRIBUTION</font></strong>. </li>
  <li> The actual target accounts are selected randomly from the range of available
    user accounts. </li>
  <li> The decision of whether a recipient is to be in the local or remote domain
    is made according to <strong><font size="-1">MSG_DESTINATION_LOCAL_PERCENT</font></strong>. </li>
  <li> The length of the message to be sent is based on <strong><font size="-1">MSG_SIZE_DISTRIBUTION</font></strong>. </li>
  <li> The speed at which the connection is handled - how much delay is inserted
    in between steps - is based on <strong><font size="-1">DATA_RATE_DISTRIBUTION</font></strong>. </li>
  <li> Every SMTP session will transmit exactly one message. </li>
</ol>
<p> For an SMTP session simulating incoming traffic from another mail server,
  the configuration parameters are applied as follows: </p>
<ol>
  <li> The number of recipients is determined according to <strong><font size="-1">MSG_RECP_DISTRIBUTION</font></strong>. </li>
  <li> The actual target accounts are selected randomly from the range of available
    user accounts. </li>
  <li> All recipients are assumed to be local.. </li>
  <li> The length of the message to be sent is based on <font size="-1"><strong>MSG_SIZE_DISTRIBUTION</strong>.</font> </li>
  <li> The connection speed is handled at full speed, without artificial delays.. </li>
  <li> Every SMTP session will transmit exactly one message. </li>
</ol>
<p> <u>The parameters which determine how many SMTP sessions of these types are
  being started each second are <strong>UserCount</strong>, <strong><font size="-1">MSG_SENT_PER_DAY</font></strong>, <strong><font size="-1">PEAK_LOAD_PERCENT</font></strong> and <strong><font size="-1">MSG_DESTINATION_LOCAL_PERCENT</font>:</strong></u></p>
<ol>
  <li> SMTP sessions simulating local users' messages are started according
    to the formula </li>
  <li style="list-style-type: none; list-style-image: none; list-style-position: outside;">
    <div style="margin-left: 2em;"> new sessions per second = <strong>UserCount</strong> * <strong><font size="-1">MSG_SENT_PER_DAY</font> * <font size="-1">PEAK_LOAD_PERCENT</font></strong> / 3600 </div>
  </li>
  <li> SMTP sessions simulating incoming traffic from other mail servers are
    started according to the formula </li>
  <li style="list-style-type: none; list-style-image: none; list-style-position: outside;">
    <div style="margin-left: 2em;"> new sessions per second = <strong>UserCount</strong> <font size="-1">* <strong>MSG_SENT_PER_DAY
          * PEAK_LOAD_PERCENT / 3600 * (1 - MSG_DESTINATION_LOCAL_PERCENT)</strong></font> </div>
  </li>
</ol>
<p> For the handling of traffic to/from remote mail servers, i.e. the role of
  the parameter <strong><font size="-1">MSG_DESTINATION_LOCAL_PERCENT</font></strong> in this context,
  please refer to section 5.2. </p>
<h4> &nbsp;<a id="4.2.2.2." name="4.2.2.2."></a>4.2.2.2&nbsp;&nbsp;&nbsp; POP3
  Session </h4>
<p> A POP session:<br>
<ol>
  <li>establishes a connection,</li>
  <li>receives the banner screen,</li>
  <li>authenticates as a local user,</li>
  <li>checks a mailbox,</li>
  <li><u>downloads</u> and <u>deletes all messages found</u>,</li>
  </li>and disconnects.</li>
</ol>
  The benchmark intentionally generates two types of POP sessions
  (see <a href="#5.3.">5.3 - POP retries</a>), but the sequence of activities is the same in each
  case. </p>
<p> The following parameters affect the simulation of a POP session: </p>
<ol>
  <li> The target account is selected randomly from either of two disjoint parts
    of the range of available test accounts (see <a href="#5.3">5.3</a>).<br>
    The parameters <font size="-1"><strong>POP_CHECKS_PER_DAY</strong></font> and <strong><font size="-1">REPEATED_POP_CHECKS_PER_DAY</font></strong> determine the percentage
    which is issued against each part. </li>
  <li> The speed at which the connection is handled - how much delay is inserted
    in between steps - is based on <strong><font size="-1">DATA_RATE_DISTRIBUTION</font></strong>. </li>
</ol>
<p> <u>How many messages are downloaded and deleted, as well as the size distribution
  of these messages, is determined by what is found in the mail store, which
  in turn is a result of earlier message-sending activity. </u></p>
<p> The parameters which determine how many POP sessions are being started each
  second are <strong>UserCount</strong>, <font size="-1">POP_CHECKS_PER_DAY</font>, <font size="-1">REPEATED_POP_CHECKS_PER_DAY</font>,&nbsp; and <font size="-1">PEAK_LOAD_PERCENT</font><strong>:</strong> </p>
<ol>
  <li><u><strong>new POP sessions against the "random" pool:</strong></u></li>
    <br>
  <center>
    <strong>UserCount * (<font size="-1">POP_CHECKS_PER_DAY - REPEATED_POP_CHECKS_PER_DAY)</font> * <font size="-1">PEAK_LOAD_PERCENT</font> / 3600</strong>
  </center>
    <br>
  <li> <u><strong>new POP sessions against the "retry" pool:</strong></u></li>
  <br>
  <center>
    <strong>UserCount * <font size="-1">REPEATED_POP_CHECKS_PER_DAY</font> * <font size="-1">PEAK_LOAD_PERCENT</font> /
    3600</strong> 
  </center>
</ol>
<h3> <a id="4.2.3." name="4.2.3."></a><font color="#000000">4.2.3. Transaction
    Workload Parameter Calculation</font> </h3>
<p> The workload definition discussed in <a href="#4.2.2.">section 4.2.2</a> leads to the following
  overall load definition. For convenience, <u>we are including the related benchmark
  metric (SPECmail2001 messages per minute) in the first column</u> - for the relationship
  between user count and benchmark metric, please refer to <a href="#4.4.">section 4.4</a>.<br>
&nbsp; </p>
<table border="1" cellspacing="0" cols="6" width="100%">
  <tbody><tr>
    <td>
      <center>
        <strong>SPECmail2001</strong><br>
        <strong>messages per minute</strong>
      </center>
    </td>
    <td>
      <center>
        related user count
      </center>
    </td>
    <td>
      <center>
        SMTP sessions<br>
        from local users<br>
        per second
      </center>
    </td>
    <td>
      <center>
        SMTP sessions from remote mail servers<br>
        per second
      </center>
    </td>
    <td>
      <center>
        (initial (!))<br>
        POP checks<br>
        per second
      </center>
    </td>
    <td>
      <center>
        (repeated)<br>
        POP checks<br>
        per second
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        <strong>500</strong>
      </center>
    </td>
    <td>
      <center>
        100,000
      </center>
    </td>
    <td>
      <center>
        8.33
      </center>
    </td>
    <td>
      <center>
        7.50
      </center>
    </td>
    <td>
      <center>
        4.17
      </center>
    </td>
    <td>
      <center>
        12.50
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        <strong>1,000</strong>
      </center>
    </td>
    <td>
      <center>
        200,000
      </center>
    </td>
    <td>
      <center>
        16.67
      </center>
    </td>
    <td>
      <center>
        15.00
      </center>
    </td>
    <td>
      <center>
        8.33
      </center>
    </td>
    <td>
      <center>
        25.00
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        <strong>1,500</strong>
      </center>
    </td>
    <td>
      <center>
        300,000
      </center>
    </td>
    <td>
      <center>
        25.00
      </center>
    </td>
    <td>
      <center>
        22.50
      </center>
    </td>
    <td>
      <center>
        12.50
      </center>
    </td>
    <td>
      <center>
        37.50
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        <strong>2,000</strong>
      </center>
    </td>
    <td>
      <center>
        400,000
      </center>
    </td>
    <td>
      <center>
        33.33
      </center>
    </td>
    <td>
      <center>
        30.00
      </center>
    </td>
    <td>
      <center>
        16.67
      </center>
    </td>
    <td>
      <center>
        50.00
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        <strong>2,500</strong>
      </center>
    </td>
    <td>
      <center>
        500,000
      </center>
    </td>
    <td>
      <center>
        41.67
      </center>
    </td>
    <td>
      <center>
        37.50
      </center>
    </td>
    <td>
      <center>
        20.83
      </center>
    </td>
    <td>
      <center>
        62.50
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        <strong>3,000</strong>
      </center>
    </td>
    <td>
      <center>
        600,000
      </center>
    </td>
    <td>
      <center>
        50.00
      </center>
    </td>
    <td>
      <center>
        45.00
      </center>
    </td>
    <td>
      <center>
        25.00
      </center>
    </td>
    <td>
      <center>
        75.00
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        <strong>3,500</strong>
      </center>
    </td>
    <td>
      <center>
        700,000
      </center>
    </td>
    <td>
      <center>
        58.33
      </center>
    </td>
    <td>
      <center>
        52.50
      </center>
    </td>
    <td>
      <center>
        29.17
      </center>
    </td>
    <td>
      <center>
        87.50
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        <strong>4,000</strong>
      </center>
    </td>
    <td>
      <center>
        800,000
      </center>
    </td>
    <td>
      <center>
        66.67
      </center>
    </td>
    <td>
      <center>
        60.00
      </center>
    </td>
    <td>
      <center>
        33.33
      </center>
    </td>
    <td>
      <center>
        100.00
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        <strong>4,500</strong>
      </center>
    </td>
    <td>
      <center>
        900,000
      </center>
    </td>
    <td>
      <center>
        75.00
      </center>
    </td>
    <td>
      <center>
        67.50
      </center>
    </td>
    <td>
      <center>
        37.50
      </center>
    </td>
    <td>
      <center>
        112.50
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        <strong>5,000</strong>
      </center>
    </td>
    <td>
      <center>
        1,000,000
      </center>
    </td>
    <td>
      <center>
        83.33
      </center>
    </td>
    <td>
      <center>
        75.00
      </center>
    </td>
    <td>
      <center>
        41.67
      </center>
    </td>
    <td>
      <center>
        125.00
      </center>
    </td>
  </tr>
</tbody></table>
<h2> <a id="4.3." name="4.3."></a>4.3. <font color="#000000">Pre-population of
    the Mail Store</font> </h2>
<p> The benchmark tool pre-populates the mail store before the first benchmark
  run. This initialization step uses SMTP sessions to deposit messages in the
  test accounts. The distribution is based on the workload parameters of the
  benchmark (<a href="#4.2.">see section 4.2</a>). The benchmark performs some analytic computation
  (<a href="#4.3.2">see section 4.3.2</a>) to determine which distribution will be the steady state
  of the mail server under the defined load. The benchmark tool provide the initialization
  functionality as a separable step (-initonly),<u> and performs a verification
  of the message distribution before each test run.</u> </p>
<p> An important feature of the benchmark's workload definition is that the
  mail server, when exposed to repeated test runs, will enter into a steady state.
  While messages get added and removed, the overall count, as well as the distribution
  across test accounts, will fluctuate only statistically. Overall, the mail
  store will neither fill up and overflow (assuming safe sizing), nor will it
  empty out. </p>
<p> This allows the tester to run repeated benchmark runs back-to-back on the
  same setup without the need for re-initialization. It is also explicitly acceptable
  for the tester to backup and restore an initialized mail store. </p>
<p> The number of test accounts is a minimum requirement - the tester is free
  to establish a larger mail store with surplus test accounts, e.g. to experiment
  with supportable load levels, or to benchmark different hardware configurations
  on the same setup. </p>
<p> The rationale for these decisions is: </p>
<ol>
  <li> flexibility for a series of tests </li>
  <li> there is no portable method to prevent the backup/restore of a mail server
    contents; even a human reviewer would have a hard time proving that it has
    happened </li>
  <li> although not exactly realistic, a de-fragmented mail store is at least
    a level playing field. Again, even if backup/restore were not allowed, defragmentation
    utilities could be used in between test runs, without a chance for verification
    by the test tool. </li>
  <li> The only significantly more realistic benchmark method would require including
    a long-time (24+-hour) burn-in run, included with the benchmark run. </li>
</ol>
<h3> <a id="4.3.1." name="4.3.1."></a><font color="#000000">4.3.1. Pre-populated
    Mail Store Calculation</font> </h3>
<p> The transaction workload leads to a mail server steady state. The resulting
  distribution of messages over mailboxes has been computed as follows (please
  refer to subsequent section for the analytical background):<br>
&nbsp; </p>
<center>
  <table border="1" cellspacing="0" cols="6">
    <tbody><tr align="center" valign="bottom">
      <td> <font face="Arial">Message Count</font> </td>
      <td> <font face="Arial">Percent</font> </td>
      <td> <font face="Arial">Message Count</font> </td>
      <td> <font face="Arial">Percent</font> </td>
      <td> <font face="Arial">Message Count</font> </td>
      <td> <font face="Arial">Percent</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">0</font> </td>
      <td style=""> <font face="Arial">26.50%</font> </td>
      <td> <font face="Arial">10</font> </td>
      <td style=""> <font face="Arial">1.80%</font> </td>
      <td> <font face="Arial">20</font> </td>
      <td style=""> <font face="Arial">0.16%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">1</font> </td>
      <td style=""> <font face="Arial">16.11%</font> </td>
      <td> <font face="Arial">11</font> </td>
      <td style=""> <font face="Arial">1.42%</font> </td>
      <td> <font face="Arial">21</font> </td>
      <td style=""> <font face="Arial">0.13%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">2</font> </td>
      <td style=""> <font face="Arial">12.25%</font> </td>
      <td> <font face="Arial">12</font> </td>
      <td style=""> <font face="Arial">1.12%</font> </td>
      <td> <font face="Arial">22</font> </td>
      <td style=""> <font face="Arial">0.10%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">3</font> </td>
      <td style=""> <font face="Arial">9.61%</font> </td>
      <td> <font face="Arial">13</font> </td>
      <td style=""> <font face="Arial">0.88%</font> </td>
      <td> <font face="Arial">23</font> </td>
      <td style=""> <font face="Arial">0.08%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">4</font> </td>
      <td style=""> <font face="Arial">7.56%</font> </td>
      <td> <font face="Arial">14</font> </td>
      <td style=""> <font face="Arial">0.69%</font> </td>
      <td> <font face="Arial">24</font> </td>
      <td style=""> <font face="Arial">0.06%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">5</font> </td>
      <td style=""> <font face="Arial">5.95%</font> </td>
      <td> <font face="Arial">15</font> </td>
      <td style=""> <font face="Arial">0.54%</font> </td>
      <td> <font face="Arial">25</font> </td>
      <td style=""> <font face="Arial">0.05%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">6</font> </td>
      <td style=""> <font face="Arial">4.68%</font> </td>
      <td> <font face="Arial">16</font> </td>
      <td style=""> <font face="Arial">0.43%</font> </td>
      <td> <font face="Arial">26</font> </td>
      <td style=""> <font face="Arial">0.04%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">7</font> </td>
      <td style=""> <font face="Arial">3.69%</font> </td>
      <td> <font face="Arial">17</font> </td>
      <td style=""> <font face="Arial">0.34%</font> </td>
      <td> <font face="Arial">27</font> </td>
      <td style=""> <font face="Arial">0.03%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">8</font> </td>
      <td style=""> <font face="Arial">2.90%</font> </td>
      <td> <font face="Arial">18</font> </td>
      <td style=""> <font face="Arial">0.27%</font> </td>
      <td> <font face="Arial">28</font> </td>
      <td style=""> <font face="Arial">0.02%</font> </td>
    </tr>
    <tr align="center" valign="bottom">
      <td> <font face="Arial">9</font> </td>
      <td style=""> <font face="Arial">2.29%</font> </td>
      <td> <font face="Arial">19</font> </td>
      <td style=""> <font face="Arial">0.21%</font> </td>
      <td> <font face="Arial">29</font> </td>
      <td style=""> <font face="Arial">0.02%</font> </td>
    </tr>
    </tbody><caption align="bottom">
    Table 2: Message distribution over mailboxes.
    </caption>
  </table>
</center>
<p> <img alt="" src="./img/MsgCount21.gif" height="623" width="911"> </p>
<p> <u>This distribution reflects an average message count of 3.43 messages per
  mailbox - which is in line with expectations (PopMsgsRcvd).</u> </p>
<p> The average message count per mailbox is a base figure for estimating the
  size of the mail store. </p>
<p> For a test setup for 1 million users, the total message count in the mail
  store (average over time) is </p>
<ol>
  <li> MsgsRcvd * UserCount </li>
  <li style="list-style-type: none; list-style-image: none; list-style-position: outside;"> <br>
    = 3.43 * 1,000,000<br>
    = <strong>3,430,000</strong> </li>
</ol>
<p> and the overall raw message data volume is </p>
<ol>
  <li> MsgsRcvd * UserCount * MsgSz </li>
  <li style="list-style-type: none; list-style-image: none; list-style-position: outside;"> <br>
    = 3.43 * 1,000,000 * 25 KB<br>
    = <strong>86 GB</strong> </li>
</ol>
<p> It is important to note that this is just the raw amount of message data
  to be expected on average in the mail store. "On average over time" -
  that means, the benchmark does not guarantee it will stay at exactly that level.
  A margin of at least 25% is recommended to be added before diving into any
  further assumptions. </p>
<p> Furthermore, there are further factors with potentially significant impact
  to be taken into account before determining a safe storage size for the intended
  benchmark. That is a server-specific planning process, therefore we can't
  give generally applicable sizing rules here. It is strongly recommended to
  take not just this overall raw size, but at least the file count (plus 25%
  headroom) and the message size distribution into the capacity planning process
  of the target mail server. Further aspects of the user profile may be relevant,
  too. The following factors may play a role: </p>
<ol>
  <li> file system and/or database overhead (directories, indexes) </li>
  <li> internal and external fragmentation - note that the majority of messages
    are very small </li>
  <li> file system reserve space (working close to a file system's capacity
    often means loss in throughput) </li>
  <li> extra disk space in case the mail server uses delayed physical deletion
    of messages (only logical deletion is required as part of the benchmark) </li>
  <li> disk space needed for interim queuing of messages, as well as for logging
    mail server operation. </li>
</ol>
<p> Last but not least, disk configuration for a mail server is not strictly
  a size issue; performance (IO throughput) plays a significant role, too.&nbsp; </p>
<h3> <a id="4.3.2." name="4.3.2."></a><font color="#000000">4.3.2. Analytical
    Background</font> </h3>
<p> This section describes how the steady-state mail store definition has been
  determined. It provides purely the mathematical background and is not needed
  to understand and run the benchmark. </p>
<p> The benchmark separates mailboxes into two pools: a pool for initial POP
  checks and a pool for simulating repeated POP checks. The following calculation
  looks only into the pool for initial POP checks. </p>
<p> Let </p>
<blockquote> <tt>PopRate be the rate at which a mailbox gets emptied out</tt><br>
  <tt>SmtpRate be the rate at which additional messages hit a mailbox</tt> </blockquote>
<p> Note, the time basis does not play a role here, as long as it is the same
  in both cases. </p>
<p> First, compute </p>
<blockquote> <tt>p[0] = the percentage of mailboxes that is empty</tt><br>
  <tt>&nbsp;&nbsp;&nbsp; (= the probability that a mailbox is empty)</tt> </blockquote>
<p> If one observes p[0] along the time axis, then a "new" p[0]' can
  be computed from an "old" p[0] as follows: </p>
<blockquote> <tt>p[0]' = the old percentage of empty mailboxes</tt><br>
  <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MINUS the portion that received
  mail</tt><br>
  <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PLUS the portion of previously
  non-empty mailboxes that got POP-checked</tt> </blockquote>
<p> in mathematical terms </p>
<blockquote> <tt>p[0]' = p[0] - p[0] * SmtpRate + (1 - p[0]) * PopRate</tt> </blockquote>
<p> Since we assume the mail store has reached steady state, that probability
  does not change over time, </p>
<blockquote> <tt>p[0]' = p[0]</tt> </blockquote>
<p> and this becomes </p>
<blockquote> <tt>p[0] = p[0] - p[0] * SmtpRate + (1 - p[0]) * PopRate</tt> </blockquote>
<p> Subtract p[0] on both sides, eliminate the parenthesis: </p>
<blockquote> <tt>0 = - p[0] * SmtpRate + PopRate - p[0] * PopRate</tt> </blockquote>
<p> Isolate terms with p[0]: </p>
<blockquote> <tt>p[0] * (SmtpRate + PopRate) = PopRate</tt> </blockquote>
<p> Isolate p[0] by dividing by its factor (which is non-zero): </p>
<blockquote> <strong><tt>p[0] = PopRate / (SmtpRate + PopRate)</tt></strong> </blockquote>
<p> Now, compute </p>
<blockquote> <tt>p[i] = the percentage of mailboxes with i messages (i &gt; 0)</tt><br>
  <tt>&nbsp;&nbsp;&nbsp; (= the probability that a mailbox contains i messages)</tt> </blockquote>
<p> A "new" p[i]' can be computed from an "old" p[i]
  as follows: </p>
<blockquote> <tt>p[i]' = the old percentage of mailboxes with i messages</tt><br>
  <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MINUS the portion that received
  mail (and now has i+1 messages)</tt><br>
  <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MINUS the portion that got POP-checked</tt><br>
  <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PLUS the portion of mailboxes
  with i-1 messages that received mail</tt> </blockquote>
<p> in mathematical terms </p>
<blockquote> <tt>p[i]' = p[i] - p[i] * SmtpRate - p[i] * PopRate + p[i-1]
    * SmtpRate</tt> </blockquote>
<p> Since we assume the mail store has reached steady state, that probability
  does not change over time, </p>
<blockquote> <tt>p[i]' = p[i]</tt> </blockquote>
<p> thus </p>
<blockquote> <tt>p[i] = p[i] - p[i] * SmtpRate - p[i] * PopRate + p[i-1] * SmtpRate</tt> </blockquote>
<p> Isolate terms with p[i]: </p>
<blockquote> <tt>p[i] * (1 - 1 + SmtpRate + PopRate) = p[i-1] * SmtpRate</tt> </blockquote>
<p> simplified: </p>
<blockquote> <tt>p[i] * (SmtpRate + PopRate) = p[i-1] * SmtpRate</tt> </blockquote>
<p> Dividing by the factor of p[i], which is non-zero: </p>
<blockquote> <strong><tt>p[i] = p[i-1] * SmtpRate / (SmtpRate + PopRate)</tt></strong> </blockquote>
<p> In order to apply these formulae to the SPECmail2001 workload parameters,
  we need to make a forward reference to section 5.3, where we'll discuss
  how the benchmark implements the repeated POP attempts against the same account.
  The repeated POP attempts introduce an asymmetry into an otherwise completely
  random process which could be nicely analyzed with a single application of
  the above rules. </p>
<p> Suffice it to say that the implementation of the POP Retries splits the set
  of test accounts into two parts: the retry pool and the random pool. Each pool
  follows the aforementioned scheme, but with different parameters. </p>
<p> For the random pool, we have: </p>
<blockquote> <tt>percentage of account in random pool:&nbsp; 92.5%</tt><br>
  <tt>SmtpRate:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.925
  * 4.00 = 3.70</tt><br>
  <tt>PopRate:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
1.00</tt> </blockquote>
<p> and therefore: </p>
<blockquote> <tt>p[0] = PopRate / (SmtpRate + PopRate)</tt><br>
  <tt>&nbsp;&nbsp;&nbsp;&nbsp; = 1.00 / (3.70 + 1.00)</tt><br>
  <tt>&nbsp;&nbsp;&nbsp;&nbsp; = 21.28%</tt>
  <p> <tt>p[1] = p[0] * SmtpRate / (SmtpRate + PopRate)</tt><br>
    <tt>&nbsp;&nbsp;&nbsp;&nbsp; = 0.21276 * 3.7 / (3.7 + 1.00</tt><br>
    <tt>&nbsp;&nbsp;&nbsp;&nbsp; = 16.75%</tt> </p>
  <p> <tt>p[2] = p[1] * 3.70 / 4.70</tt><br>
    <tt>&nbsp;&nbsp;&nbsp;&nbsp; = 13.19%</tt> </p>
  <p> <tt>...</tt> </p>
</blockquote>
<p> For the retry pool, we have: </p>
<blockquote> <tt>percentage of account in random pool:&nbsp;&nbsp; 7.5%</tt><br>
  <tt>SmtpRate:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.075
  * 4.00 = 0.30</tt><br>
  <tt>PopRate:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
3.00</tt> </blockquote>
<p> and therefore: </p>
<blockquote> <tt>p[0] = PopRate / (SmtpRate + PopRate)</tt><br>
  <tt>&nbsp;&nbsp;&nbsp;&nbsp; = 3.00 / (0.30 + 3.00)</tt><br>
  <tt>&nbsp;&nbsp;&nbsp;&nbsp; = 90.91%</tt>
  <p> <tt>p[1] = p[0] * SmtpRate / (SmtpRate + PopRate)</tt><br>
    <tt>&nbsp;&nbsp;&nbsp;&nbsp; = 0.90909 * 0.3 / (0.3 + 3.00)</tt><br>
    <tt>&nbsp;&nbsp;&nbsp;&nbsp; = 8.26%</tt> </p>
  <p> <tt>p[2] = p[1] * 0.30 / 3.30</tt><br>
    <tt>&nbsp;&nbsp;&nbsp;&nbsp; = 0.75%</tt> </p>
  <p> <tt>...</tt> </p>
</blockquote>
<p> In order to compute the combined distribution, these two series need to be
  combined into a weighted average (92.5% of the first series, 7.5% from the
  second series). The result is reflected in the table given at the beginning
  of section 4.3.1.&nbsp; </p>
<h2> <a id="4.4." name="4.4."></a><font color="#000000">4.4. Benchmark Metric
    Calculation</font> </h2>
<p> The transaction mix resulting from the profile, relative to a single SMTP
  message sent by a POP consumer user, is:<br>
&nbsp; </p>
<center>
  <table border="1" cellspacing="0" width="70%" >
    <tbody><tr>
      <td> <u>Transaction Type </u></td>
      <td> <u>Transaction Count per Minute </u></td>
    </tr>
    <tr>
      <td> message sent by user </td>
      <td align="center"> 1 </td>
    </tr>
    <tr>
      <td> message sent to remote mail server </td>
      <td align="center"> 0.9 </td>
    </tr>
    <tr>
      <td> message received from remote mail server </td>
      <td align="center"> 0.9 </td>
    </tr>
    <tr>
      <td> mailbox check </td>
      <td align="center"> 2 </td>
    </tr>
    <tr>
      <td> retrieval and deletion of message </td>
      <td align="center"> 2 </td>
    </tr>
    </tbody><caption align="bottom">
    Table 4: Transaction mix
    </caption>
  </table>
</center>
<p> With the user profile given above, it was already shown that 1 million users
  will generate 83.3 SMTP messages per second, which equals 5,000 SMTP messages
  per minute. Since the transaction mix contains exactly 1 SMTP message, we have
  the basic equation<br>
&nbsp;<br>
&nbsp; </p>
<center>
  <table border="0">
    <tbody><tr>
      <td>
        <p align="center"> <tt>5,000 SPECmail2001 messages per minute = 1,000,000
            supported POP consumer users</tt> </p>
        <p align="center"> <tt>which is equivalent to</tt> </p>
      </td>
    </tr>
  </tbody></table>
</center>
<br>
<p>&nbsp; </p>
<center>
  <table bgcolor="#cccccc" border="0">
    <tbody><tr>
      <td align="center"> <br>
        <strong><tt>&nbsp;<font size="+2">1 SPECmail2001 messages per minute&nbsp;</font></tt></strong>
        <p> <strong><tt><font size="+2">=</font></tt></strong> </p>
        <p> <strong><tt><font size="+2">200 supported POP consumer users</font></tt></strong><br>
&nbsp; </p>
      </td>
    </tr>
  </tbody></table>
</center>
<p> The following table lists a number of translations between the two quantities
  (note that SPECmail2001 ratings are not limited to entries in this table.)<br>
&nbsp; </p>
<table border="1" cellspacing="0" cols="6" width="100%">
  <tbody><tr>
    <td>
      <center>
        Supported POP<br>
        consumer users
      </center>
    </td>
    <td>
      <center>
        SPECmail2001<br>
        messages per minute
      </center>
    </td>
    <td>
      <center>
        Supported POP<br>
        consumer users
      </center>
    </td>
    <td>
      <center>
        SPECmail2001<br>
        messages per minute
      </center>
    </td>
    <td>
      <center>
        Supported POP<br>
        consumer users
      </center>
    </td>
    <td>
      <center>
        SPECmail2001<br>
        messages per minute
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        1,000
      </center>
    </td>
    <td>
      <center>
        5
      </center>
    </td>
    <td>
      <center>
        10,000
      </center>
    </td>
    <td>
      <center>
        50
      </center>
    </td>
    <td>
      <center>
        100,000
      </center>
    </td>
    <td>
      <center>
        500
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        2,000
      </center>
    </td>
    <td>
      <center>
        10
      </center>
    </td>
    <td>
      <center>
        20,000
      </center>
    </td>
    <td>
      <center>
        100
      </center>
    </td>
    <td>
      <center>
        200,000
      </center>
    </td>
    <td>
      <center>
        1,000
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        3,000
      </center>
    </td>
    <td>
      <center>
        15
      </center>
    </td>
    <td>
      <center>
        30,000
      </center>
    </td>
    <td>
      <center>
        150
      </center>
    </td>
    <td>
      <center>
        300,000
      </center>
    </td>
    <td>
      <center>
        1,500
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        4,000
      </center>
    </td>
    <td>
      <center>
        20
      </center>
    </td>
    <td>
      <center>
        40,000
      </center>
    </td>
    <td>
      <center>
        200
      </center>
    </td>
    <td>
      <center>
        400,000
      </center>
    </td>
    <td>
      <center>
        2,000
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        5,000
      </center>
    </td>
    <td>
      <center>
        25
      </center>
    </td>
    <td>
      <center>
        50,000
      </center>
    </td>
    <td>
      <center>
        250
      </center>
    </td>
    <td>
      <center>
        500,000
      </center>
    </td>
    <td>
      <center>
        2,500
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        6,000
      </center>
    </td>
    <td>
      <center>
        30
      </center>
    </td>
    <td>
      <center>
        60,000
      </center>
    </td>
    <td>
      <center>
        300
      </center>
    </td>
    <td>
      <center>
        600,000
      </center>
    </td>
    <td>
      <center>
        3,000
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        7,000
      </center>
    </td>
    <td>
      <center>
        35
      </center>
    </td>
    <td>
      <center>
        70,000
      </center>
    </td>
    <td>
      <center>
        350
      </center>
    </td>
    <td>
      <center>
        700,000
      </center>
    </td>
    <td>
      <center>
        3,500
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        8,000
      </center>
    </td>
    <td>
      <center>
        40
      </center>
    </td>
    <td>
      <center>
        80,000
      </center>
    </td>
    <td>
      <center>
        400
      </center>
    </td>
    <td>
      <center>
        800,000
      </center>
    </td>
    <td>
      <center>
        4,000
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        9,000
      </center>
    </td>
    <td>
      <center>
        45
      </center>
    </td>
    <td>
      <center>
        90,000
      </center>
    </td>
    <td>
      <center>
        450
      </center>
    </td>
    <td>
      <center>
        900,000
      </center>
    </td>
    <td>
      <center>
        4,500
      </center>
    </td>
  </tr>
  <tr>
    <td>
      <center>
        10,000
      </center>
    </td>
    <td>
      <center>
        50
      </center>
    </td>
    <td>
      <center>
        100,000
      </center>
    </td>
    <td>
      <center>
        500
      </center>
    </td>
    <td>
      <center>
        1,000,000
      </center>
    </td>
    <td>
      <center>
        5,000
      </center>
    </td>
  </tr>
  </tbody><caption align="bottom">
  Table 5: Relationship between user count and messages per minute
  </caption>
</table>
<p> <em><font size="-1">See also Q&amp;A section: <a href="#Q9">Does SPECmail2001
        consider mailing lists?</a></font></em><br>
  <em><font size="-1">See also Q&amp;A section: <a href="#Q6">Why does the SPECmail2001
  benchmark emphasize on putting as much mail into the mail server as it is taking
  out?</a></font></em> </p>
<h2> <a id="4.5." name="4.5."></a>4.5. Mail Server Housekeeping Functions </h2>
<p> Besides the actual workload, the system under test (SUT) is expected to run
  under normal operating conditions, assuming the production environment of a
  real-life ISP. The only required function identified to fall into this category
  is logging, basically: </p>
<ol>
  <li> one log entry per SMTP session and </li>
  <li> one log entry per POP/IMAP session. </li>
</ol>
<em><font size="-1">See also Q&amp;A section: <a href="#Q8">Does the mail server
have to actually, physically delete messages while it is performing the benchmark?</a></font></em>
<p>&nbsp; </p>
<h1> <a id="5." name="5."></a>5. Detail Aspects of Workload Simulation </h1>
<p> This chapter discusses select details of how the workload is generated. The
  material presented here is getting close to description of the benchmark tool
  implementation, but it is regarded as closely related to the workload definition. </p>
<h2> <a id="5.1." name="5.1."></a>5.1. Arrival Rate and Interarrival Time Distribution </h2>
<p> SPECmail2001 is designed to generate the workload as close to real-world
  situation as possible. In the real world, the load results from many independent
  clients issuing requests, with no coordination with, or knowledge about each
  other. A key aspect of this scenario is that even a high load on the mail server,
  which typically leads to slower responses, won't discourage new clients
  from showing up. Each of the many clients produces only a tiny fraction of
  the total load. </p>
<h3> <a id="5.1.1." name="5.1.1."></a>5.1.1. Arrival Rate </h3>
<p> <u>SPECmail2001 generates the workload at a defined average rate of requests
  per unit of time - <b>the arrival rate.</b></u> In order to understand the significance
  of this method, one needs to look at the alternative. A benchmark could also
  put load on the server "as fast as it will go". While that might
  lead to a faster determination of a peak rate, there are some disadvantages.
  Under such a load, the mail server could conveniently "throttle" the
  load dynamically - when ever things get critical, its response time would go
  up, and therefore the load down. It would also be more difficult to control
  a correct load mix - a server might serve more requests of the type which are
  convenient for it. Finally, response times might become unacceptable, and therefore
  the reported rate meaningless. SPECmail2001 avoids all of these disadvantages.&nbsp; </p>
<h3> <a id="5.1.2." name="5.1.2."></a>5.1.2. Interarrival Time </h3>
<p> <u>A second aspect of generating the workload is the <b>interarrival time distribution.</b></u>
  A standard assumption for this distribution, in a system with many independent
  arrivals is the exponential distribution. A study of log data from a mail server
  showed that a Weibull distribution fitted the distribution better. For the
  reader's convenience, here are two graphs showing the shape of these distributions. </p>
<p> <img alt="" src="./img/ExpDist1.gif" height="623" width="911"> </p>
<p> <img alt="" src="./img/Weibull1.gif" height="623" width="911"><br>
  A distinguishing aspect of the Weibull distribution is that it shows a lower
    probability for very short interarrival times. Since this distinction depends
    a lot on how much the timestamps in the logs can be trusted, at the very
    low end, discussion ensued whether the Weibull distribution was really the
    correct answer here. The suspicion was expressed that artifacts of the conditions
    of the workload study may have been at play here. </p>
<ol>
  <li> Log data do not correctly reflect when the events actually happened -
    they reflect when the server got around to processing them. Any serialization
    effect between the arrival of the events - be it the hardware (a single processor),
    the OS (a single driver handling both requests), the mail server (a single
    thread accepting both connections, or a single thread generating and time-stamping
    log events) - would make very low interarrival times less likely to be recorded
    as such in the log. </li>
</ol>
<ol>
  <li> Timestamp granularity - in the given case, to full seconds - has an effect
    on accuracy of evaluation, too. A simulation was done by a member of the
    working group which started with a series of exponentially-distributed interarrival
    times, truncated them to full seconds, and generated the resulting interrival
    time picture. It had a similar effect in the curve. </li>
</ol>
<p> As a practical matter, and certainly a contributing factor in the discussion,
  the Weibull distribution is very difficult to implement correctly in a distributed
  load generator environment. <u>The exponential distribution has the convenient
  feature that the overlaid effect of several exponentially-distributed event
  streams is once again exponentially distributed. The load can therefore be
  split up between N load generator systems, and each can do its work independently</u>.
  The same is not true for the Weibull distribution. <u>Correct implementation would
  need to pay special attention to the very small interarrival times</u>. Distributed
  load generators could achieve that only through near-perfect clock synchronization.
  This would have added another level of complexity to the execution of this
  benchmark: time synchronization, potentially across different platforms. </p>
<p> The workgroup therefore decided to accept the theory <u>"exponential distribution
  in = Weibull distribution out" (meaning, if a mail server gets triggered
  with events according to an exponential distribution, it may very well log
  events with a Weibull distribution)</u>, and to base the benchmark on the exponential
  distribution. </p>
<p> <em><font size="-1">See also Q&amp;A section: <a href="#Q31">Why does the
        benchmark emphasize on generating requests at a certain arrival rate
        and pattern?</a></font></em>&nbsp; </p>
<h2> <a id="5.2." name="5.2."></a>5.2. Traffic to/from Remote Mail Servers </h2>
<font color="#000000">SPECmail2001 includes mail exchange with external mail
servers. For a consumer ISP, a majority of the mail sent will go to users of
other ISP's. Vice versa, the majority of the mail received comes from external
users. The reason for this lies in the fact that the users of one ISP are typically
not a tight-knit community; they have more external than internal email contacts.</font>
<p> <font color="#000000">SPECmail2001 assumes that 90% of the messages sent
    are going to external users (i.e. are forwarded to remote mail servers),
    and that 90% of the mail received by users originated from external users
    (i.e. is received from remote mail servers). The following diagram shows
    the real mail flow that would result from this assumption.</font>&nbsp;<br>
  <br>
</p>
<center>
  <p> <img alt="" src="./img/Remote1.gif" height="531" width="459"> </p>
</center>
<p> <br>
  <br>
</p>
<p> SPECmail2001 simulates this external mail exchange by </p>
<ol>
  <li> generating the messages received from external mail servers using its
    load generators, and </li>
  <li> providing a Mail Sink component to which the server-under-test sends all
    messages for external destinations. The Mail Sink does not simulate transfer
    or response time delays. </li>
</ol>
<p> The effective mail flow looks as follows:<br>
&nbsp;<br>
</p>
<center>
  <p> <img alt="" src="./img/Remote2.gif" height="531" width="459"> </p>
</center>
<p> <br>
  <br>
</p>
<p> SPECmail2001 "integrates" the incoming mail from remote servers
  with the mail sent by local users. Accordingly, a few factors get adjusted,
  compared to what one would expect from the user profile: </p>
<ol>
  <li> the rate at which SMTP messages are sent increases </li>
  <li> the distribution local vs. remote gets adjusted </li>
  <li> the percentage of messages sent at modem speed gets adjusted, since all
    incoming traffic from remote mail servers is assumed to happen at full network
    speed. </li>
</ol>
<p> This adjustment is done according to the following formulae. The variable
  names do not reflect tool configuration parameter names or tool-internal variable
  names; they have been choosen to be self-explanatory for the purpose of this
  discussion.. Given </p>
<blockquote> &nbsp;
  <table bgcolor="#cccccc">
    <tbody><tr>
      <td> <tt>SmtpArrivalsFromUsersPerSec</tt> <br>
        <tt>SmtpFromUserToRemotePercent</tt> <br>
        <tt>SmtpFromUserModemPercentage</tt> </td>
    </tr>
  </tbody></table>
</blockquote>
<p> Then </p>
<blockquote> &nbsp;
  <table bgcolor="#cccccc">
    <tbody><tr>
      <td> <tt>SmtpTotalArrivalsPerSec =</tt> <br>
        <tt>&nbsp;&nbsp;&nbsp; (1 + SmtpFromUserToRemotePercentage) * SmtpArrivalsFromUsersPerSec</tt> </td>
    </tr>
  </tbody></table>
</blockquote>
<p> and </p>
<blockquote> &nbsp;
  <table bgcolor="#cccccc">
    <tbody><tr>
      <td> <tt>SmtpEffectiveRemotePercentage =</tt> <br>
        <tt>&nbsp;&nbsp;&nbsp; SmtpFromUserToRemotePercentage / (1 + SmtpFromUserToRemotePercentage)</tt> </td>
    </tr>
  </tbody></table>
</blockquote>
<p> and </p>
<blockquote> &nbsp;
  <table bgcolor="#cccccc">
    <tbody><tr>
      <td> <tt>SmtpEffectiveModemPercentage =</tt> <br>
        <tt>&nbsp;&nbsp;&nbsp; SmtpFromUserModemPercentage / (1 + SmtpFromUserToRemotePercentage)</tt> </td>
    </tr>
  </tbody></table>
</blockquote>
<p> Using the same numbers as in the diagrams, here is an example: </p>
<ol>
  <li> users are sending 100 messages into the server </li>
  <li> 90% of the traffic (90 messages) are assumed to go to an external mail
    server </li>
  <li> Due to the assumption that the amount of mail sent to the Internet equals
    the amount received from the Internet, 90 messages are assumed to come in
    from the Internet. All of these get added to the mail store, since they are
    directed at local users. </li>
  <li> 100 messages (10 from local users, 90 from the Internet) end up in the
    local mail store </li>
  <li> 80% of the user-originated mail traffic are specified as modem traffic,
    i.e. 80 (of 100) messages </li>
</ol>
<p> In this example case, the benchmark tool would therefore </p>
<ol>
  <li> generate 190 (instead of 100) SMTP messages </li>
  <li> send 47.3% to as outbound mail to remote addresses, so that they end up
    in the mail sink </li>
  <li> send 52.7% to local addresses, so that they end up in the mail store. </li>
  <li> send 42.1% (80 of 190) SMTP messages at modem-bandwidth speed. </li>
</ol>
<p> Note, all remote communication of the mail server is assumed to be at full
  network speed, hence the Mail Sink does not simulate any bandwidth limitation.&nbsp; </p>
<h2> <a id="5.3." name="5.3."></a><font color="#000000">5.3. POP Retries</font> </h2>
<p> POP users typically have set up their email client so that it performs periodic
  mailbox checks after a defined interval. From the point of the mail server,
  this generates a load on mailboxes which have recently been checked and which
  in all likeliness are empty. Overall, the vast majority of POP sessions is
  logged as "empty", i.e. no messages are being downloaded. </p>
<p> The main aspects of this load are that the mailboxes are typically empty,
  and that they have recently been checked. Both aspects may have effects on
  the mail server's efficiency to handle requests on these mailboxes. The
  benchmark simulates this special load by setting aside a portion of the test
  accounts (referred to as the "retry pool") for use by frequent repeat
  checks, while performing exclusively "initial" POP checks against
  the remainder (the "random pool"). While not in line with what is
  going on in reality, it does implement the main aspects (typically empty accounts,
  recently checked), and it simplified the implementation since it did not introduce
  complex state management of test accounts. </p>
<p> We mentioned potential benefits, i.e. aspects which make accessing these
  test accounts easier for the mail server. Caching of repeatedly used information
  is a good strategy; that's why the benchmark addresses this specific aspects
  of a POP3 workload. </p>
<p> However, there is also a potential down-side to be taken into account here
  - according to the POP3 specification, the mail server may keep an account
  locked for a certain period of time (5 minutes). Therefore the benchmark needs
  to avoid overly aggressive repeated accesses to the same test account. The
  configuration parameter <strong><font size="-1">REPEATED_POP_CHECK_INTERVAL_SECONDS</font></strong> specifies
  the minimum time interval after which a mailbox is being checked again. The
  conforming setting of this parameter is 300 seconds. In practice, a re-check
  of a mailbox in the retry pool will happen between this time, and twice that
  duration (under the conforming setting, between 300 and 600 seconds). </p>
<p> The size of the retry pool is determined so that the minimum re-check interval
  is safely observed AND so that the size of the pool is appropriate for all
  three load levels (80/100/120%). Changing the retry pool size would mean disturbing
  the steady state of the mail server, therefore it needs to be avoided. For
  the conforming parameter setting, 7.5% of the mailboxes will be assigned to
  the retry pool, leaving 92.5% for the mainline operation. </p>
<p> On the SMTP side, there is no special consideration for the retry pool: messages
  are sent randomly against all test accounts without consideration for random
  vs. retry pools. While checking of Delivery Time is going on on a mailbox,
  it is protected from any unrelated POP activity, be it initial POPs or POP
  retries. </p>
<p> The mailboxes for the retry pool are being selected at random by the benchmark
  tool on each run, in a way that is compliant with the steady state. </p>
<p> If the tester changes the overall user count, in order to verify another
  load level, then the steady state of the mail server is maintained - since
  the different or additional set of mailboxes will contain its own portion of
  candidates for the retry pool.&nbsp; </p>
<h1> <a id="6." name="6."></a>6. Quality of Service </h1>
<p> SPECmail2001 accepts only throughput claims which are proven while maintaining
  some minimal Quality of Service (QoS). There are two aspects to quality of
  service - the interactive response time of the mail server to each protocol
  step, as directly or indirectly observed by the user, and the delivery time
  that it takes to make a message available to a (local) recipient. The SPECmail2001
  QoS standard are meant to support high-quality mail service, rather than promote
  barely acceptable service levels. </p>
<h2> <a id="6.1." name="6.1."></a>6.1. Response Times </h2>
<p> Response times of the server, in reaction to each request, are measured by
  the benchmark tool, with an accuracy of approx. 0.1 seconds. The clock starts
  before sending the request, and it stops when the response, or the first packet
  thereof, is received. </p>
<p> Among the requests issues by SPECmail2001, there are two - SMTP-data and
  POP-retr - whose response time depends on the amount of data being transmitted.
  The response time criteria are therefore split into two groups. </p>
<p> For all requests <u>other than SMTP-data and POP-retr</u>, SPECmail2001 requires
  that, for each request type, </p>
<blockquote> <strong>95% of all response times</strong> </blockquote>
<p> must be&nbsp; under </p>
<blockquote> <strong>5 seconds.</strong> </blockquote>
<p> This may appear like a very lax standard - the rationale was to capture complex
  as well as trivial mail server requests in one number. </p>
<p> For the SMTP-data and POP-retr requests, the size of the test message, as
  well as the artificial delays inserted for modem bandwidth simulation need
  to be taken into account. The maximally allowed response time for these requests
  has two components </p>
<ol>
  <li> a base response time allowed for all requests, regardless of size </li>
  <li> an additional response time proportional to the message size </li>
</ol>
<p> The first component is </p>
<ol>
  <li> 5 seconds </li>
</ol>
<p> identical to the QoS requirement for the first group. The second component
  is computed based on the message size, requiring that </p>
<ol>
  <li> the message be transferred/accepted at at least half the modem bandwidth </li>
</ol>
<p> Note that for simplicity of implementation, the allowance for modem bandwidth
  is made, whether or not the message is actually subject to modem delay simulation.
  The rationale being that a mail server which is slowing down due to overload
  will likely do this across the board. </p>
<p> The complete formula for the QoS cutoff time for this group is therefore </p>
<ol>
  <li> <strong>5 sec + (MsgSzInBytes / (0.5 * ModemBw in bytes/s) )</strong> </li>
</ol>
<p> and, again, </p>
<ol>
  <li> <strong>95% of all requests</strong> </li>
</ol>
<p> need to meet that condition. </p>
<p> Examples </p>
<p> The modem bandwidth simulates 56.6Kbaud; we'll assume in the following
  math that this equates to 6,000 bytes/sec. The formula becomes therefore </p>
<ol>
  <li> <strong>5 sec + (MsgSzInBytes / 3,000 bytes/s ) =&nbsp;&nbsp; 5,000 ms
      + (MsgSzInBytes / 3 bytes/ms )</strong> </li>
</ol>
<p> The following table illustrates how the constant component dominates the
  effective QoS cutoff time for small messages, and how it becomes less and less
  relevant for larger message sizes.<br>
&nbsp; </p>
<center>
  <table border="1" cellspacing="0" width="50%">
    <tbody><tr>
      <td>
        <div align="right"> <tt>Message Size</tt> </div>
      </td>
      <td>
        <div align="right"> <tt>QoS Cutoff Time</tt> </div>
      </td>
    </tr>
    <tr>
      <td>
        <div align="right"> <tt>1,000 bytes</tt> </div>
      </td>
      <td>
        <div align="right"> <tt>5.000 +&nbsp;&nbsp; 0.333 =&nbsp;&nbsp; 5.3 sec</tt> </div>
      </td>
    </tr>
    <tr>
      <td>
        <div align="right"> <tt>10,000 bytes</tt> </div>
      </td>
      <td>
        <div align="right"> <tt>5.000 +&nbsp;&nbsp; 3.333 =&nbsp;&nbsp; 8.3 sec</tt> </div>
      </td>
    </tr>
    <tr>
      <td>
        <div align="right"> <tt>100,000 bytes</tt> </div>
      </td>
      <td>
        <div align="right"> <tt>5.000 +&nbsp;&nbsp; 3.333 =&nbsp; 38.3 sec</tt> </div>
      </td>
    </tr>
    <tr>
      <td>
        <div align="right"> <tt>1,000,000 bytes</tt> </div>
      </td>
      <td>
        <div align="right"> <tt>5.000 +&nbsp; 33.333 = 338.3 sec</tt> </div>
      </td>
    </tr>
    <tr>
      <td>
        <div align="right"> <tt>2,000,000 bytes</tt> </div>
      </td>
      <td>
        <div align="right"> <tt>5.000 + 666.666 = 671.7 sec</tt> </div>
      </td>
    </tr>
  </tbody></table>
</center>
<p> The benchmark tool determines the allowed response time on the fly, on a
  message-by-message basis, and maintains passed/fail counts just like for other
  QoS criteria.&nbsp; </p>
<h2> <a id="6.2." name="6.2."></a>6.2. Delivery Times </h2>
<p> Delivery time is defined as the time it takes from sending a message via
  SMTP to it becoming available to a user attempting retrieval. SPECmail2001
  performs the check for availability to the receiving user via POP attempts.
  By adding this QoS requirement, the mail server is forced to actually deliver
  the mail to the target mailboxes in a reasonable time, rather than just spooling
  it, and processing it later (e.g. after the benchmark is over). </p>
<p> SPECmail2001 requires that </p>
<blockquote> <strong>95% of all messages to local users</strong> </blockquote>
<p> get delivered to the target mailbox within </p>
<blockquote> <strong>60 seconds.</strong> </blockquote>
<p> Given that email service is traditionally more of a store-and-forward mechanism
  than a real-time application, this may appear to be a pretty strict standard.
  However, the motivation for this requirement was that email exchange is increasingly
  used as part of real-time interaction between users. </p>
<p> Implementation note: Probing for the message is the only portable way to
  find out when it gets delivered. However, this probing is overhead, and the
  resulting insert/remove patterns on the mail store are not very natural. Therefore,
  SPECmail2001 restricts the probing of submitted messages to a random sample
  of 1.00% of the overall mail traffic. </p>
<h2> <a id="6.3." name="6.3."></a>6.3. Remote Delivery </h2>
<p> Remote Delivery is only checked for count - 95% of messages sent to a remote
  address need to be reported as received by the Mail Sink within the test phase. </p>
<p> There is no measurement or verification of Remote Delivery Time. This relaxed
  measurement method eliminates the need for a synchronized system time among
  the client systems. Relying just on count still ensures that most of the necessary
  work gets done by the mail server within the test timeframe and does not get
  pushed to the time after the benchmark. </p>
<p> The requirement is </p>
<blockquote> <strong>95% of all messages to the remote mail server</strong> </blockquote>
<p> are received by the remote server within the test timeframe. </p>
<h2> <a id="6.4." name="6.4."></a>6.4. Error Rates </h2>
<p> Mail protocols, and email clients, are prepared to deal with error situations,
  like a temporarily unavailable mail server, quite gracefully. Often failed
  transactions get transparently retried. The SPECmail2001 benchmark allows therefore </p>
<blockquote> <strong>an error rate of 1%</strong> </blockquote>
<p> to still be acceptable in a valid benchmark run. It is counted as an error
  if the mail server returns an unexpected response, but also if it does not
  respond at all within 60 seconds.&nbsp; </p>
<h2> <a id="6.5." name="6.5."></a>6.5. Overall QoS Requirement </h2>
<p> SPECmail2001 requires that a mail server passes these requirements in ALL
  individual categories, i.e. each protocol step by itself, as well as the delivery
  time evaluations, must meet the requirement. As an example, 94% compliance
  in one protocol step (a failure) cannot be made up by 98% compliance in another
  protocol step. The maximum error rate condition needs to be met in addition.&nbsp; </p>
<h1> <a id="7." name="7."></a>7. Performance Characterization </h1>
<p> SPECmail2001 characterizes mail server performance by giving three data points
  and the degree of adherence to QoS requirements at these points: </p>
<ol>
  <li> The 80% mark. The mail server is running under less than the load that
    it is supposedly able to handle. A good mail server should exceed the QoS
    requirements, and report close to 100% compliance. </li>
  <li> The 100% mark, the claimed performance level of the mail server. At this
    level, the mail server needs to meet the QoS requirements, and it is expected
    it will be close to the minimum QoS level on at least one of the criteria. </li>
  <li> The 120% mark. At this higher-than-claimed load level, the mail server
    will typically no longer meet the QoS requirements. Mail servers are sometimes
    confronted with an unexpected load beyond specified limits, and should be
    able to deal with it. This data point shows how well it does. </li>
</ol>
<p> Below are examples for how better and worse mail servers, with the same claimed
  capacity (the 100% level), might fare in this characterization.<br>
&nbsp; </p>
<blockquote> &nbsp;
  <table bgcolor="#cccccc">
    <tbody><tr>
      <td> <tt>Better Server</tt>
        <p> <tt>&nbsp; 80% |XXXXXXXXXXXXXXXXXXXXXXXXXXX&nbsp;</tt><br>
          <tt>&nbsp;100% |XXXXXXXXXXXXXXXXXXXXXX</tt><br>
          <tt>&nbsp;120% |XXXXXXXXXXXXXXXX</tt><br>
          <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; +-----------+----+----+----+</tt><br>
          <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
|&nbsp;&nbsp;&nbsp; |&nbsp;&nbsp;&nbsp; |&nbsp;&nbsp;&nbsp; |</tt><br>
          <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
85&nbsp;&nbsp; 90&nbsp;&nbsp; 95&nbsp; 100</tt><br>
&nbsp; </p>
      </td>
    </tr>
  </tbody></table>
  <br>
&nbsp;
  <table bgcolor="#cccccc">
    <tbody><tr>
      <td> <tt>Worse Server</tt>
        <p> <tt>&nbsp; 80% |XXXXXXXXXXXXXXXXXXXXXX&nbsp;</tt><br>
          <tt>&nbsp;100% |XXXXXXXXXXXXXXXXXXXXXX</tt><br>
          <tt>&nbsp;120% |XXXXXXXXXXX</tt><br>
          <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; +-----------+----+----+----+&nbsp;</tt><br>
          <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
|&nbsp;&nbsp;&nbsp; |&nbsp;&nbsp;&nbsp; |&nbsp;&nbsp;&nbsp; |</tt><br>
          <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
85&nbsp;&nbsp; 90&nbsp;&nbsp; 95&nbsp; 100</tt><br>
&nbsp; </p>
      </td>
    </tr>
  </tbody></table>
</blockquote>
<p> Accordingly, a SPECmail2001 benchmark run consists of a series of warm-up,
  measurement and cool-down phases: </p>
<p> <img alt="" src="./img/Phases1.gif" height="623" width="911"> </p>
<p> Only the transaction load is varied between these three points. The pre-populated
  mail store needs to match the 100% load level (larger is OK), and does not
  vary for the 80% or the 120% test case.&nbsp; </p>
<p> <em><font size="-1">See also Q&amp;A section: <a href="#Q4">If the server
        shows full conformance of the server even 120% - why not submit that
        level as the performance metric?</a></font></em> </p>
<h1> <a id="8." name="8."></a>8. Components of a Benchmark Setup </h1>
<h2> <a id="8.1." name="8.1."></a>8.1. System Under Test (SUT) </h2>
<p> The mail server system under test is the collection of hardware and software
  that handles the requests issued by the benchmark test client systems, in all
  its aspects. Mail servers for large user communities may include a whole set
  (cluster or similar) of systems - the system under test therefore includes
  not only all processor, memory, disk hardware, but also all networking hardware
  including any switches or routers needed on the access side or inside of the
  cluster. </p>
<h2> <a id="8.2." name="8.2."></a>8.2. Benchmark Test Client Systems </h2>
<p> The benchmark test client systems are the systems running the components
  of the SPECmail2001 benchmark software. The software components are one primary
  client and one or more load generators. They can be run on one or more client
  systems. The software components work together to issue the benchmark load
  against the system under test while monitoring the server's response and
  delivery times.&nbsp; </p>
<h1> <a id="10." name="10."></a>9. Future Plans </h1>
<p> This concludes the description of the SPECmail2001 benchmark architecture.
  As all SPEC benchmarks, it is anticipated that this benchmark will evolve over
  time, and will be released in updated versions, matching changing observations
  in the field, and evolving technologies. </p>
<ol>
  <li> A follow-up version might address business-type IMAP mail users. </li>
  <li> The workload might be reviewed, based on actual traffic profile data from
    real ISPs. </li>
  <li> The mechanics of benchmark execution might get improved, by implementing "automatic
    peak finding", where the benchmark tool explores the sustainable load
    on its own. </li>
</ol>
<h1> <a id="QandA" name="QandA"></a>Appendix: Questions and Answers </h1>
<p> These are discussions which have been held during the design phase of this
  benchmark. There are hyper links throughout the text into this section, where
  the questions mattered. These considerations have been kept out of the main
  body of the document, to streamline the description of the benchmark. It was
  felt, however, that these thoughts should not simply be lost, but may help
  the understanding of the design decisions. </p>
<p> </p>
<hr width="100%">
<a id="Q1" name="Q1"></a><strong>Question:</strong>
<p> Why isn't the benchmark metric "Number of Users"? </p>
<p> <strong>Answer:</strong> Since ISP's sizes are discussed in the press
  often in terms of the size of their subscriber base, this would have been an
  intuitive choice for the benchmark metric. However, user profiles vary greatly
  from case to case, and will vary even more as technologies evolve (e.g. multi-media
  contents) and as email moves into more areas. There is easily a factor of 50
  and more between "light" and "heavy" user profiles. </p>
<p> A benchmark metric "number of users" could easily be quoted out
  of context, and could be misunderstood greatly. While the metric "messages
  per minute" is not completely fail-safe either, at least it identifies
  an actual transaction load more directly. A translation between "SPECmail2001
  messages per minute" and supported user count, according to the assumed
  user profile, is given in chapter 4. </p>
<p> </p>
<hr width="100%">
<a id="Q2" name="Q2"></a><strong>Question</strong>
<p> : Why isn't the benchmark metric "Parallel Sessions"? </p>
<p> <strong>Answer</strong>: While it is true that the number of parallel established
  sessions has been used in some proprietary mail server benchmarks, it is not
  really a good measure for the service a mail server provides. </p>
<p> With the exception of the online operation mode of IMAP, a mail server really "sees" many
  short, independent requests from email clients and other mail servers. Each
  of these is in fact a session consisting of several interrelated requests,
  but these sessions are short-lived. Their duration is not determined by anything
  like user think time, but rather by the time it takes to move the data (esp.
  over slow links) and - counter-intuitively - by the server response time. Ironically,
  the slower mail server will produce longer sessions, and will therefore show
  a higher count of parallel sessions. </p>
<p> The point isn't to have many people in your shop ... the point is to
  serve many customers. </p>
<p> </p>
<hr width="100%">
<a id="Q3" name="Q3"></a><strong>Question</strong>
<p> : Why doesn't the benchmark push as hard as possible and report the achieved
  throughput? </p>
<p> <strong>Answer</strong>: This method would be applicable if it would lead
  to peak mail server throughput, under acceptable quality of service conditions.
  This not the case with a mail server. A mail server has the option to spool
  mail to a queueing area, for processing at an arbitrary later time. This would
  deteriorate quality of service (delivery time). It would also mean that the
  work imposed by the benchmark does not necessarily get done during the measurement
  period: the server might continue to work on de-queueing the spooled messages
  after the test is over. This method might also lead to unacceptably high response
  times. </p>
<p>&nbsp; </p>
<hr width="100%">
<a id="Q31" name="Q31"></a><strong>Question</strong>
<p> : Why does the benchmark emphasize on generating requests at a certain arrival
  rate and pattern? </p>
<p> <strong>Answer</strong>: This is regarded as a key element in generating
  a real-world load scenario. A mail server needs to serve many independent clients;
  there is no way for it to "push back" by responding more slowly to
  previous requests - therefore SPECmail2001 emphasises on a constant arrival
  rate. The arrival pattern, modelled after real-world observation, eliminates
  any chance that a mail server might react unusually optimally to request sequences
  which are evenly spaced over time. </p>
<p> </p>
<hr width="100%">
<a id="Q4" name="Q4"></a><strong>Question</strong>
<p> : If the performance characterization shows full conformance of the server
  even at 120% - why did the sponsor not submit that 120% level as the actual
  performance metric? </p>
<p> <strong>Answer</strong>: A condition for the 100% level is that there is
  a matching prepopulated mail store. The mail store in question may not have
  been big enough to support the 120% load as the actual benchmark metric. </p>
<p> Another motivation could be, the QoS drop beyond the 120% mark was found
  to be too sharp by the test sponsor - the rules of SPECmail2001 allow the sponsor
  to resort to a lower performance claim and show a good 120% behavior instead.
  The price for the sponsor is the lowered benchmark metric. </p>
<p> </p>
<hr width="100%">
<a id="Q6" name="Q6"></a><strong>Question</strong>
<p> : Why does the SPECmail2001 benchmark emphasize putting as much mail into
  the mail server as it is taking out? </p>
<p> <strong>Answer</strong>: It makes it easier to run several benchmark runs
  right after each other, including the required 80% / 100% / 120% series. It
  also gives the mail server a chance to stabilize over the period of the test.
  If the store were constantly growing/shrinking, the mail server might keep
  changing its speed, and it might reach one of the boundary conditions (empty
  mail store or disk overflow). </p>
<p> </p>
<hr width="100%">
<a id="Q8" name="Q8"></a><strong>Question</strong>
<p> : Does the mail server have to actually physically delete messages while
  it is performing the benchmark? </p>
<p> <strong>Answer</strong>: No. The standard mail server protocols do not require
  that deleted mail is actually removed from the physical media at that same
  instant. So there is no way for the benchmark tool to verify that mail is physically
  deleted from the server's storage area -- and depending on the underlying
  storage technology, "deleted" may mean different things to different
  implementations. Of course, any deleted message must be "gone" from
  that mailbox, i.e. a subsequent listing of the same mailbox, from the same
  or another client, must not list deleted messages anymore -- in compliance
  with the POP and IMAP protocols. The benchmark tool does not currently verify
  that. If a mail server delays physical removal of messages (several available
  server products choose to do that), then of course the tester must configure
  disk space sufficient to cover the excess storage needs. </p>
<p> </p>
<hr width="100%">
<a id="Q9" name="Q9"></a><strong>Question</strong>
<p> : Does SPECmail2001 consider mailing lists? </p>
<p> <strong>Answer</strong>: No. Mailing list expansion is not inherent part
  of handling the IMAP, POP or SMTP protocol. This task is often not performed
  by the main mail server, but by dedicated systems. ISPs typically do not offer
  mailing lists as a service to their users. Our workload studies, which we used
  as the basis of defining the workload of the benchmark, were performed on mail
  servers which saw the result of mailing list expansion - so in a way, the net
  effect, the duplication of messages, was implicitly taken into account. </p>
<p> </p>
<hr width="100%">
<a id="Q10" name="Q10"></a><strong>Question</strong>
<p> : Why does SPECmail2001 not include IMAP4 users? </p>
<p> <strong>Answer</strong>: This was originally intended, as the near-complete
  coverage of IMAP in the architecture paper, and the existing coverage of IMAP
  testing options in the benchmark tool show. Mainly due to the inability to
  identify practical workload patterns for IMAP, but also to reduce risk in completing
  the first release of this benchmark, the design team decided to drop IMAP4
  from the workload mix. There was also concern about the practical value of
  a mixed POP/IMAP benchmark: actual mail server installations are often dedicated
  to (mainly) one or the other protocol. The initial workload (the amount of
  data on disks) per user is also considerably different ... even a minority
  of IMAP users in the mix tends to dominate the disk usage. These issues will
  be reviewed and should lead to coverage of IMAP4 by a "SPECmail200x" benchmark
  soon. </p>
<p>&nbsp; </p>
<hr width="100%">
<a id="Q11" name="Q11"></a><strong>Question</strong>
<p> : Does SPECmail2001 consider WebMail? </p>
<p> <strong>Answer</strong>: No. WebMail is outside the scope of the SPECmail2001
  benchmark. </p>
<p>&nbsp; </p>
<hr width="100%">
<a id="Q12" name="Q12"></a><strong>Question</strong>
<p> : What constitutes a mail server, in the sense of SPECmail2001? </p>
<p> <strong>Answer</strong>: A mail server is defined as the collection of all
  systems, including storage, internal and front-end networking hardware, required
  to handle the specified mail server load. Hardware to provide directory service
  as far as needed to handle the mail load is part of the system under test.
  The mail server can be made up of multiple nodes, as long as it appears to
  the outside as a single mail server. The list of requirements to qualify as
  a single mail server includes that all accounts are within one domain, and
  every change to the mail server (insertion or removal of a message) is visible
  consistently across the complete system. It is legal for the mail server to
  provide different IP addresses for the different protocols, but only one IP
  address per protocol. The mail server must not require that user load traffic
  can be coming in, separated in any way (e.g. by protocol) onto separate networks.
  Any router hardware achieving such separation needs to be listed as part of
  the system under test. For details refer to the Run Rules. </p>
<p>&nbsp; </p>
<hr width="100%">
<strong>Question</strong>
<p> : Doesn't a real mail server require much more disk space? </p>
<p> <strong>Answer</strong>: Yes. While SPECmail2001 makes a serious attempt
  at requiring a mail store appropriate for the number of users the system under
  test claims to support, it is still a compromise between reality and the cost
  of a benchmark. The increased disk space needed in real installations results
  largely from two factors. First, there is the spool area. The spool area tends
  to fill up if external mail servers are not available for receiving mail -
  a scenario which is not included in this benchmark. Second, there is a class
  of users which are not reflected in the SPECmail2001 profile - users who leave
  their mail on the server. Their disk space usage isn't really determined
  by the amount of mail they receive/retrieve on a regular basis, but by the
  quota and cleanup policy the ISP imposes on them. In a way, one can think of
  the disk space absorbed by such long-term storage as "dead space" -
  it contributes to size of occupied disks, size of file systems and/or database
  indices, but it does not contribute to the actual transaction load. </p>
<p> Copyright  2001 Standard Performance Evaluation Corporation </p>
</body></html>
